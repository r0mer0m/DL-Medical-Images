{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "from core import * \n",
    "from data_manipulation import Transform, RandomRotation, Flip, RandomCrop, normalize_imagenet, normalize_mura, center_crop\n",
    "from utils import save_model, load_model, lr_loss_plot\n",
    "from architectures import DenseNet121\n",
    "from train_functions import OptimizerWrapper, TrainingPolicy, FinderPolicy, validate_multilabel, lr_finder, validate_binary, TTA_binary\n",
    "import json\n",
    "\n",
    "SEED = 42\n",
    "R_PIX = 8\n",
    "IDX = 10 # Emphysema\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "TRANSFORMATIONS = [RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=R_PIX)]\n",
    "NORMALIZE = True # ImageNet\n",
    "FREEZE = True\n",
    "GRADUAL_UNFREEZING = True\n",
    "n_samples = [50,100,200,400,600,800,1000]\n",
    "\n",
    "\n",
    "\n",
    "BASE_PATH = Path('../..')\n",
    "PATH = BASE_PATH/'data'\n",
    "CHESTXRAY_FOLDER = PATH/'ChestXRay-250'\n",
    "CHEXPERT_FOLDER = PATH/'ChesXPert-250'\n",
    "\n",
    "SAVE_DIRECTORY = Path('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chesxray_train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "chesxray_valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "chesxray_test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "\n",
    "chexpert_train_df = pd.read_csv(PATH/\"CheXpert-v1.0-small/train.csv\")\n",
    "chexpert_valid_df = pd.read_csv(PATH/\"CheXpert-v1.0-small/valid.csv\")\n",
    "\n",
    "chexpert_train_df = train_df[train_df['Frontal/Lateral']==\"Frontal\"]\n",
    "chexpert_valid_df = valid_df[valid_df['Frontal/Lateral']==\"Frontal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data frame labeled data subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labels(df_col):\n",
    "    return np.array(list(map(np.array, df_col.str.split(' ')))).astype(int)\n",
    "\n",
    "def subset_df(df, amt=None, idx=IDX):\n",
    "    \n",
    "    lbls = decode_labels(df.Label)\n",
    "    \n",
    "    if amt is None: amt=2*lbls[:,idx].sum()\n",
    "    \n",
    "    pos_idxs = lbls[:,idx].astype(bool)\n",
    "\n",
    "    neg = df[~pos_idxs].sample(n=amt//2, replace=False)\n",
    "    pos = df[pos_idxs].sample(n=amt//2, replace=False)\n",
    "\n",
    "    return pd.concat([neg, pos]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chesxray_valid_df_balanced = subset_df(chesxray_valid_df, amt=None, idx=IDX)\n",
    "chesxray_test_df_balanced = subset_df(chesxray_test_df, amt=None, idx=IDX)\n",
    "\n",
    "amt = 1000\n",
    "chesxray_train_df_balanced = subset_df(chesxray_train_df, amt, idx=IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Basic Images DataSet\n",
    "\n",
    "    Args:\n",
    "        dataframe with data: image_file, label\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, image_path, idx):\n",
    "        self.image_files = df[\"ImageIndex\"].values\n",
    "        self.lables = np.array([obs.split(\" \")[idx]\n",
    "                                for obs in df.Label]).astype(np.float32)\n",
    "        self.image_path = image_path\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.image_path / self.image_files[index]\n",
    "        x = cv2.imread(str(path)).astype(np.float32)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) / 255\n",
    "        y = self.lables[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    \n",
    "class UnlabeledDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Basic Images DataSet\n",
    "\n",
    "    Args:\n",
    "        dataframe with data: image_file, label\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, image_path):\n",
    "        self.image_files = ['_'.join(p.split('/')[1:]) for p in df[\"Path\"].values]\n",
    "        self.image_path = image_path\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.image_path / self.image_files[index]\n",
    "        x = cv2.imread(str(path)).astype(np.float32)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) / 255\n",
    "\n",
    "        return x, None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnlabeledTransform():\n",
    "    \"\"\" Rotates an image by deg degrees\n",
    "\n",
    "    Args:\n",
    "\n",
    "        dataset: A base torch.utils.data.Dataset of images\n",
    "        transforms: list with all the transformations involving randomnes\n",
    "\n",
    "        Ex:\n",
    "            ds_transform = Transform(ds, [random_crop(240, 240), rotate_cv()])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, transforms=None, normalize=True, seed=42, r_pix=8):\n",
    "        self.dataset, self.transforms = dataset, transforms\n",
    "\n",
    "        if normalize is True: self.normalize = normalize_imagenet\n",
    "        elif normalize=='MURA': self.normalize = normalize_mura\n",
    "        else: self.normalize = False\n",
    "\n",
    "        self.center_crop = partial(center_crop, r_pix=r_pix)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Do transformation when image is called.\n",
    "        We are assuming the trainingvalidation set is read from a folder of images already\n",
    "        noramlized and resized to before random-crop and after random-crop sizes respectively.\n",
    "\n",
    "        \"\"\"\n",
    "        data, label = self.dataset[index]\n",
    "        \n",
    "        out = np.copy(data)\n",
    "\n",
    "        if self.transforms:\n",
    "            for choices, f in list(zip(self.choices, self.transforms)):\n",
    "                args = {k: v[index] for k, v in choices.items()}\n",
    "                out = f(out, **args)\n",
    "        else:\n",
    "            out=self.center_crop(im=out)\n",
    "        \n",
    "        data = self.center_crop(data)\n",
    "\n",
    "        if self.normalize: \n",
    "            out = self.normalize(out)\n",
    "            data = self.normalize(data)\n",
    "            \n",
    "        return np.rollaxis(out, 2), np.rollaxis(data, 2)\n",
    "\n",
    "\n",
    "    def set_random_choices(self):\n",
    "        \"\"\"\n",
    "        To be called at the begining of every epoch to generate the random numbers\n",
    "        for all iterations and transformations.\n",
    "        \"\"\"\n",
    "        self.choices = []\n",
    "        x_shape = self.dataset[0][0].shape\n",
    "        N = len(self)\n",
    "\n",
    "        for t in self.transforms:\n",
    "            self.choices.append(t.set_random_choices(N, x_shape))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBatches:\n",
    "    '''\n",
    "    Creates a dataloader using the specificed data frame with the dataset corresponding to \"data\".\n",
    "    '''\n",
    "\n",
    "    def __init__(self, df, transforms, shuffle, img_folder_path, idx=IDX, batch_size=16, num_workers=8,\n",
    "                 drop_last=False, r_pix=8, normalize=True, seed=42, problem_type='supervised'):\n",
    "\n",
    "        if problem_type=='supervised':\n",
    "            self.dataset = Transform(LabeledDataSet(df, image_path=img_folder_path, idx=idx),\n",
    "                                     transforms=transforms, normalize=normalize, seed=seed, r_pix=r_pix)\n",
    "        elif problem_type=='unsupervised':\n",
    "            self.dataset = UnlabeledTransform(UnlabeledDataSet(df, image_path=img_folder_path),\n",
    "                                     transforms=transforms, normalize=normalize, seed=seed, r_pix=r_pix)\n",
    "        self.dataloader = DataLoader(\n",
    "            self.dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True,\n",
    "            shuffle=shuffle, drop_last=drop_last\n",
    "        )\n",
    "\n",
    "    def __iter__(self): return ((x.cuda().float(), y.cuda().float()) for (x, y) in self.dataloader)\n",
    "\n",
    "    def __len__(self): return len(self.dataloader)\n",
    "\n",
    "    def set_random_choices(self):\n",
    "        if hasattr(self.dataset, \"set_random_choices\"): self.dataset.set_random_choices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_training = DataBatches(chesxray_train_df_balanced, TRANSFORMATIONS, idx=IDX, shuffle=True, img_folder_path=CHESTXRAY_FOLDER, batch_size=16, num_workers=8,\n",
    "                 drop_last=False, r_pix=8, normalize=True, seed=42, problem_type='supervised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 234, 234]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "labeled_training.set_random_choices()\n",
    "x,y = next(iter(labeled_training))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_training = DataBatches(chexpert_train_df, TRANSFORMATIONS, shuffle=True, img_folder_path=CHEXPERT_FOLDER, batch_size=16, num_workers=8,\n",
    "                 drop_last=False, r_pix=8, normalize=True, seed=42, problem_type='unsupervised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 184, 230]) torch.Size([16, 3, 184, 230])\n"
     ]
    }
   ],
   "source": [
    "unlabeled_training.set_random_choices()\n",
    "x,y = next(iter(unlabeled_training))\n",
    "print(x.shape, y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
