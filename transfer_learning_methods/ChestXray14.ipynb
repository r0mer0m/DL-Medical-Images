{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we illustrate how **regular training** is performed in our experiments, write the script to train in a range of (small) training samples and plot the results of this script.\n",
    "\n",
    "## How is it organized?\n",
    "\n",
    "1. In the first section notebook we illustrate the scenario were ImageNet is used with gradual unfreezing for the whole dataset. This is useful to test how the model behaves when all the data is available. \n",
    "\n",
    "2. In the second section the script is written and we explore different alternatives in transfer learning for a range of training data. We do so by combining regular training with multiple alternatives in transfer learning:\n",
    "\n",
    "    * Is transfer learning used? If so, from what dataset?  We contemplate ImageNet and MURA (general and medical images respectively).\n",
    "    * How is transfer learning done? previous CNN as feature extractor, fine-tune CNN? If we fine-tune, do we use differential learning rates?\n",
    "    * Do we do progressive unfreezing?\n",
    "\n",
    " Some of those options are excluding and other are complementary. For instance, no transfer learning and using the previous CNN as feature extractor are excluding.\n",
    "\n",
    "3. In the last section we plot the results of running the script.\n",
    "\n",
    "## I want to dig deeper\n",
    "\n",
    "This notebook's main purpose is illustrating how **regular training** is used. All other aspects are imported from `data_manipulation`,`utils`, `architectures` and `train_functions`. If the reader wants to dig dipper in aspects such as how data augmentation is implemented, what policy we use for the learning rate or how the optimizer is used we point them to the modules mentioned above. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all the available data\n",
    "## Imports & global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys; sys.path.append(\"/data/miguel/practicum/DL-Medical-Physics\")\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "from core import *\n",
    "from data_manipulation import DataBatches, RandomRotation, Flip, RandomCrop\n",
    "from utils import save_model, load_model, lr_loss_plot\n",
    "from architectures import DenseNet121\n",
    "from train_functions import get_optimizer, FinderPolicy, OptimizerWrapper, validate_multilabel, lr_finder\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "TRANSFORMATIONS = [RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=8)]\n",
    "PRETRAINED = True\n",
    "\n",
    "BASE_PATH = Path('/data/miguel/practicum/')\n",
    "PATH = BASE_PATH/'data'\n",
    "SAVE_DATA = BASE_PATH/'output/real_data_experiments/multilabel/results'\n",
    "SAVE_DIRECTORY = BASE_PATH/'output/real_data_experiments/multilabel/models'\n",
    "# SAVE_PLOT = Path('../latest_plots/14diseases-app1')\n",
    "\n",
    "IMG_FOLDER = PATH/'ChestXRay-250'\n",
    "DATA = '14diseases'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data preparation\n",
    "train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS, \n",
    "                       shuffle=True, data=DATA,batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "valid_dl = DataBatches(valid_df,img_folder_path=IMG_FOLDER, transforms = False,\n",
    "                       shuffle = False, data=DATA, batch_size = BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms = TRANSFORMATIONS, \n",
    "                      shuffle = False, data=DATA, batch_size = BATCH_SIZE, normalize=PRETRAINED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f49b19e5c846119f72c61a3e71bd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702743e684a34f17b42131fd09d43588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEaCAYAAADqqhd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DenseNet121(14, pretrained=PRETRAINED, freeze=False).cuda()\n",
    "lrs, losses  = lr_finder(model, 1, train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_annealing(start_lr, end_lr, n_iterations):\n",
    "    i = np.arange(n_iterations)\n",
    "    c_i = 1 + np.cos(i * np.pi / n_iterations)\n",
    "    return end_lr + (start_lr - end_lr) / 2 * c_i\n",
    "\n",
    "class TrainingPolicy:\n",
    "    '''Cretes the lr and momentum policy'''\n",
    "\n",
    "    def __init__(self, n_epochs, dl, max_lr, pctg=.3, moms=(.95, .85),\n",
    "                 delta=1e-4, div_factor=25.):\n",
    "        \n",
    "        total_iterations = n_epochs * len(dl)\n",
    "\n",
    "        iter1 = int(total_iterations * pctg)\n",
    "        iter2 = total_iterations - int(total_iterations * pctg)\n",
    "        iterations = (iter1, iter2)\n",
    "\n",
    "        min_start = max_lr / div_factor\n",
    "        min_end = min_start * delta\n",
    "\n",
    "        lr_segments = ((min_start, max_lr), (max_lr, min_end))\n",
    "        mom_segments = (moms, (moms[1], moms[0]))\n",
    "\n",
    "        self.lr_schedule = self._create_schedule(lr_segments, iterations)\n",
    "        self.mom_schedule = self._create_schedule(mom_segments, iterations)\n",
    "\n",
    "        self.idx = -1\n",
    "\n",
    "    def _create_schedule(self, segments, iterations):\n",
    "        '''\n",
    "        Creates a schedule given a function, behaviour and size\n",
    "        '''\n",
    "        stages = [cos_annealing(start, end, n) for ((start, end), n) in zip(segments, iterations)]\n",
    "        return np.concatenate(stages)\n",
    "\n",
    "    def step(self):\n",
    "        self.idx += 1\n",
    "        return self.lr_schedule[self.idx], self.mom_schedule[self.idx]\n",
    "    \n",
    "def one_cycle_train(n_epochs, train_dl, valid_dl, model, max_lr=.01, wd=0, alpha=1./ 3,\n",
    "          save_path=None, unfreeze_during_loop:tuple=None):\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "\n",
    "    best_loss = np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    policy = TrainingPolicy(n_epochs=n_epochs, dl=train_dl, max_lr=max_lr)\n",
    "    optimizer = OptimizerWrapper(model, policy, wd=wd, alpha=alpha)\n",
    "\n",
    "    for epoch in tqdm_notebook(range(n_epochs), ):\n",
    "        model.train()\n",
    "        agg_div = 0\n",
    "        agg_loss = 0\n",
    "        train_dl.set_random_choices()\n",
    "        for x, y in tqdm_notebook(train_dl, leave=False):\n",
    "\n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            agg_loss += batch*loss.item()\n",
    "            agg_div += batch\n",
    "            cnt += 1\n",
    "\n",
    "\n",
    "        val_loss, measure, _ = validate_multilabel(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - train loss {agg_loss/agg_div:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if save_path and val_loss < best_loss:\n",
    "            save_model(model, save_path)\n",
    "            best_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No transfer learning (done in previous experiment)\n",
    "* CNN as feature extractor.\n",
    "* Fine-tune all CNN at once, equal learning rates.\n",
    "* Gradual unfreezing with differential learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a653fee21742c7bbe43646ed055f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af07c7c80434c42a2fbda729649720a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.1691 -  val loss 0.1617 AUC 0.6390\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c346b3d917ae4866bd2704f992b97e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-927c7b26e19b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRETRAINED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mone_cycle_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfreeze_during_loop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgradual_unfreezing\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-34911279cead>\u001b[0m in \u001b[0;36mone_cycle_train\u001b[0;34m(n_epochs, train_dl, valid_dl, model, max_lr, wd, alpha, save_path, unfreeze_during_loop)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msecond_unfreeze\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/practicum/DL-Medical-Physics/architectures.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveAvgPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DenseLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CNN as feature extractor\n",
    "freeze = True\n",
    "gradual_unfreezing = False\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS,\n",
    "                       shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "model = DenseNet121(14, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "save_path = None\n",
    "one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fine-tune all CNN at once, equal learning rates\n",
    "freeze = False\n",
    "gradual_unfreezing = False\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS,\n",
    "                       shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "model = DenseNet121(14, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "save_path = None\n",
    "one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradual unfreezing with differential learning rates\n",
    "freeze = True\n",
    "gradual_unfreezing = True\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS,\n",
    "                       shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "model = DenseNet121(14, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "save_path = None\n",
    "one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1./3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_model(model, save_pathc)\n",
    "test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms = TRANSFORMATIONS, \n",
    "                      shuffle = False, data=DATA, batch_size = BATCH_SIZE, normalize=PRETRAINED)\n",
    "TTA_multilabel(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample range: Writing script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the different combinations on a script. Observe that we have constructed the training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chestxray14.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chestxray14.py\n",
    "\n",
    "import sys; sys.path.append(\"/data/miguel/practicum/DL-Medical-Physics\")\n",
    "\n",
    "from core import *\n",
    "from data_manipulation import DataBatches, RandomRotation, Flip, RandomCrop\n",
    "from utils import save_model, load_model, lr_loss_plot\n",
    "from architectures import DenseNet121\n",
    "from train_functions import get_optimizer, FinderPolicy, OptimizerWrapper, validate_multilabel, TTA_multilabel\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "TRANSFORMATIONS = [RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=8)]\n",
    "DATA = '14diseases'\n",
    "\n",
    "SAMPLE_AMOUNTS = [50,100,200,400,600,800,1000,1200,1400,1600,1800,2000]\n",
    "\n",
    "BASE_PATH = Path('/data/miguel/practicum/')\n",
    "PATH = BASE_PATH/'data'\n",
    "SAVE_DIRECTORY = BASE_PATH/'DL-Medical-Physics/transfer_learning_methods/models'\n",
    "SAVE_DATA = BASE_PATH/'DL-Medical-Physics/transfer_learning_methods/results'\n",
    "IMG_FOLDER = PATH/'ChestXRay-250'\n",
    "PRETRAINED = True # Imagenet\n",
    "\n",
    "\n",
    "def cos_annealing(start_lr, end_lr, n_iterations):\n",
    "    i = np.arange(n_iterations)\n",
    "    c_i = 1 + np.cos(i * np.pi / n_iterations)\n",
    "    return end_lr + (start_lr - end_lr) / 2 * c_i\n",
    "\n",
    "class TrainingPolicy:\n",
    "    '''Cretes the lr and momentum policy'''\n",
    "\n",
    "    def __init__(self, n_epochs, dl, max_lr, pctg=.3, moms=(.95, .85),\n",
    "                 delta=1e-4, div_factor=25.):\n",
    "        \n",
    "        total_iterations = n_epochs * len(dl)\n",
    "\n",
    "        iter1 = int(total_iterations * pctg)\n",
    "        iter2 = total_iterations - int(total_iterations * pctg)\n",
    "        iterations = (iter1, iter2)\n",
    "\n",
    "        min_start = max_lr / div_factor\n",
    "        min_end = min_start * delta\n",
    "\n",
    "        lr_segments = ((min_start, max_lr), (max_lr, min_end))\n",
    "        mom_segments = (moms, (moms[1], moms[0]))\n",
    "\n",
    "        self.lr_schedule = self._create_schedule(lr_segments, iterations)\n",
    "        self.mom_schedule = self._create_schedule(mom_segments, iterations)\n",
    "\n",
    "        self.idx = -1\n",
    "\n",
    "    def _create_schedule(self, segments, iterations):\n",
    "        '''\n",
    "        Creates a schedule given a function, behaviour and size\n",
    "        '''\n",
    "        stages = [cos_annealing(start, end, n) for ((start, end), n) in zip(segments, iterations)]\n",
    "        return np.concatenate(stages)\n",
    "\n",
    "    def step(self):\n",
    "        self.idx += 1\n",
    "        return self.lr_schedule[self.idx], self.mom_schedule[self.idx]\n",
    "    \n",
    "def one_cycle_train(n_epochs, train_dl, valid_dl, model, max_lr=.01, wd=0, alpha=1./ 3,\n",
    "          save_path=None, unfreeze_during_loop:tuple=None):\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "\n",
    "    best_loss = np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    policy = TrainingPolicy(n_epochs=n_epochs, dl=train_dl, max_lr=max_lr)\n",
    "    optimizer = OptimizerWrapper(model, policy, wd=wd, alpha=alpha)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        agg_div = 0\n",
    "        agg_loss = 0\n",
    "        train_dl.set_random_choices()\n",
    "        for x, y in train_dl:\n",
    "\n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            agg_loss += batch*loss.item()\n",
    "            agg_div += batch\n",
    "            cnt += 1\n",
    "\n",
    "\n",
    "        val_loss, measure, _ = validate_multilabel(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - train loss {agg_loss/agg_div:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if save_path and val_loss < best_loss:\n",
    "            save_model(model, save_path)\n",
    "            best_loss = val_loss\n",
    "\n",
    "# Training            \n",
    "train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "\n",
    "valid_dl = DataBatches(valid_df,img_folder_path=IMG_FOLDER,transforms=False, \n",
    "                       shuffle=False, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "train_df = train_df.sample(frac=1)\n",
    "\n",
    "for N in SAMPLE_AMOUNTS:\n",
    "\n",
    "    df = train_df[:N]\n",
    "\n",
    "    train_dl = DataBatches(df, img_folder_path=IMG_FOLDER, transforms=TRANSFORMATIONS, \n",
    "                           shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "    freeze = True\n",
    "    gradual_unfreezing = False    \n",
    "\n",
    "    model = DenseNet121(14, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "\n",
    "    save_path = SAVE_DIRECTORY/f\"chestxray14-feature-extractor-{N}.pth\"\n",
    "\n",
    "    one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=save_path, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)\n",
    "\n",
    "    freeze = False\n",
    "    gradual_unfreezing = False\n",
    "    \n",
    "    model = DenseNet121(14, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "\n",
    "    save_path = SAVE_DIRECTORY/f\"chestxray14-fine-tune-all-{N}.pth\"\n",
    "    \n",
    "    one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=save_path, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)\n",
    "    \n",
    "    freeze = True\n",
    "    gradual_unfreezing = True\n",
    "    \n",
    "    model = DenseNet121(14, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "\n",
    "    save_path = SAVE_DIRECTORY/f\"chestxray14-grad-unfr-diff-lr-{N}.pth\"\n",
    "    \n",
    "    one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=save_path, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)\n",
    "    \n",
    "# Evaluation\n",
    "\n",
    "test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "feature_extractor = {\n",
    "    'losses':[],\n",
    "    'aucs':[]\n",
    "}\n",
    "fine_tune_all = {\n",
    "    'losses':[],\n",
    "    'aucs':[]\n",
    "}\n",
    "grad_unfr_diff_lr = {\n",
    "    'losses':[],\n",
    "    'aucs':[]\n",
    "}\n",
    "\n",
    "test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms=TRANSFORMATIONS, \n",
    "                      shuffle=False, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "for i, N in enumerate(SAMPLE_AMOUNTS):\n",
    "\n",
    "    model = DenseNet121(14, pretrained=PRETRAINED, freeze=FREEZE).cuda()\n",
    "\n",
    "    load_path = SAVE_DIRECTORY/f\"chestxray14-feature-extractor-{N}.pth\"\n",
    "\n",
    "    load_model(model, load_path)\n",
    "\n",
    "    loss, mean_auc, _ = TTA_multilabel(model, test_dl, ndl=4)\n",
    "\n",
    "    feature_extractor['losses'].append(loss)\n",
    "    feature_extractor['aucs'].append(mean_auc)\n",
    "\n",
    "    load_path = SAVE_DIRECTORY/f\"chestxray14-fine-tune-all-{N}.pth\"\n",
    "\n",
    "    load_model(model, load_path)\n",
    "\n",
    "    loss, mean_auc, _ = TTA_multilabel(model, test_dl, ndl=4)\n",
    "\n",
    "    fine_tune_all['losses'].append(loss)\n",
    "    fine_tune_all['aucs'].append(mean_auc)\n",
    "    \n",
    "    save_path = SAVE_DIRECTORY/f\"chestxray14-grad-unfr-diff-lr-training-{N}.pth\"\n",
    "\n",
    "    load_model(model, load_path)\n",
    "\n",
    "    loss, mean_auc, _ = TTA_multilabel(model, test_dl, ndl=4)\n",
    "\n",
    "    grad_unfr_diff_lr['losses'].append(loss)\n",
    "    grad_unfr_diff_lr['aucs'].append(mean_auc)\n",
    "\n",
    "feature_extractor = json.dumps(feature_extractor)\n",
    "with open('results/chestxray14_feature_extractor.json', 'w') as f:\n",
    "    f.write(feature_extractor)\n",
    "\n",
    "fine_tune_all = json.dumps(fine_tune_all)\n",
    "with open('results/chestxray14_fine_tune_all.json', 'w') as f:\n",
    "    f.write(fine_tune_all)\n",
    "    \n",
    "grad_unfr_diff_lr = json.dumps(grad_unfr_diff_lr)\n",
    "with open('results/chestxray14_grad_unfr_diff_lr.json', 'w') as f:\n",
    "    f.write(grad_unfr_diff_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
