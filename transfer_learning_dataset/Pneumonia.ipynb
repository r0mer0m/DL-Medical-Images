{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we illustrate how **regular training** is performed in our experiments, write the script to train in a range of (small) training samples and plot the results of this script.\n",
    "\n",
    "## How is it organized?\n",
    "\n",
    "1. In the first section notebook we illustrate the scenario were ImageNet is used with gradual unfreezing for the whole dataset. This is useful to test how the model behaves when all the data is available. \n",
    "\n",
    "2. In the second section the script is written and we explore different alternatives in transfer learning for a range of training data. We do so by combining regular training with multiple alternatives in transfer learning:\n",
    "\n",
    "    * Is transfer learning used? If so, from what dataset?  We contemplate ImageNet and MURA (general and medical images respectively).\n",
    "    * How is transfer learning done? previous CNN as feature extractor, fine-tune CNN? If we fine-tune, do we use differential learning rates?\n",
    "    * Do we do progressive unfreezing?\n",
    "\n",
    " Some of those options are excluding and other are complementary. For instance, no transfer learning and using the previous CNN as feature extractor are excluding.\n",
    "\n",
    "3. In the last section we plot the results of running the script.\n",
    "\n",
    "## I want to dig deeper\n",
    "\n",
    "This notebook's main purpose is illustrating how **regular training** is used. All other aspects are imported from `data_manipulation`,`utils`, `architectures` and `train_functions`. If the reader wants to dig dipper in aspects such as how data augmentation is implemented, what policy we use for the learning rate or how the optimizer is used we point them to the modules mentioned above. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all the available data\n",
    "## Imports & global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys; sys.path.append(\"/data/miguel/practicum/DL-Medical-Physics\")\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "from core import *\n",
    "from data_manipulation import DataBatches, RandomRotation, Flip, RandomCrop, balance_obs, multi_label_2_binary\n",
    "from utils import save_model, load_model, lr_loss_plot\n",
    "from architectures import DenseNet121\n",
    "from train_functions import get_optimizer, FinderPolicy, OptimizerWrapper, validate_binary, lr_finder, TTA_binary\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "TRANSFORMATIONS = [RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=8)]\n",
    "PRETRAINED = True\n",
    "\n",
    "BASE_PATH = Path('/data/miguel/practicum/')\n",
    "PATH = BASE_PATH/'data'\n",
    "# SAVE_DATA = BASE_PATH/'output/real_data_experiments/multilabel/results'\n",
    "# SAVE_DIRECTORY = BASE_PATH/'output/real_data_experiments/multilabel/models'\n",
    "# SAVE_PLOT = Path('../latest_plots/14diseases-app1')\n",
    "\n",
    "IMG_FOLDER = PATH/'ChestXRay-250'\n",
    "DATA = 'Pneumonia'\n",
    "\n",
    "idx2tgt = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "tgt2idx = {disease: i for i, disease in enumerate(idx2tgt)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data preparation\n",
    "train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "train_df = multi_label_2_binary(train_df, tgt2idx['Pneumonia'])\n",
    "sample_train_df = balance_obs(train_df, amt=2000)\n",
    "\n",
    "valid_df = multi_label_2_binary(valid_df, tgt2idx['Pneumonia'])\n",
    "valid_df = balance_obs(valid_df, amt=2*len(valid_df[valid_df['Label']==1]))\n",
    "\n",
    "test_df = multi_label_2_binary(test_df, tgt2idx['Pneumonia'])\n",
    "test_df = balance_obs(test_df, amt=2*len(test_df[test_df['Label']==1]))\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS, \n",
    "                       shuffle=True, data=DATA,batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "valid_dl = DataBatches(valid_df,img_folder_path=IMG_FOLDER, transforms = False,\n",
    "                       shuffle = False, data=DATA, batch_size = BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms = TRANSFORMATIONS, \n",
    "                      shuffle = False, data=DATA, batch_size = BATCH_SIZE, normalize=PRETRAINED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa75d2865ba4710b6a6925c675122e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e20b46fd5545da8275f70fc5348354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEaCAYAAADqqhd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n67EK2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DenseNet121(1, pretrained=PRETRAINED, freeze=False).cuda()\n",
    "lrs, losses  = lr_finder(model, 1, train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_annealing(start_lr, end_lr, n_iterations):\n",
    "    i = np.arange(n_iterations)\n",
    "    c_i = 1 + np.cos(i * np.pi / n_iterations)\n",
    "    return end_lr + (start_lr - end_lr) / 2 * c_i\n",
    "\n",
    "class TrainingPolicy:\n",
    "    '''Cretes the lr and momentum policy'''\n",
    "\n",
    "    def __init__(self, n_epochs, dl, max_lr, pctg=.3, moms=(.95, .85),\n",
    "                 delta=1e-4, div_factor=25.):\n",
    "        \n",
    "        total_iterations = n_epochs * len(dl)\n",
    "\n",
    "        iter1 = int(total_iterations * pctg)\n",
    "        iter2 = total_iterations - int(total_iterations * pctg)\n",
    "        iterations = (iter1, iter2)\n",
    "\n",
    "        min_start = max_lr / div_factor\n",
    "        min_end = min_start * delta\n",
    "\n",
    "        lr_segments = ((min_start, max_lr), (max_lr, min_end))\n",
    "        mom_segments = (moms, (moms[1], moms[0]))\n",
    "\n",
    "        self.lr_schedule = self._create_schedule(lr_segments, iterations)\n",
    "        self.mom_schedule = self._create_schedule(mom_segments, iterations)\n",
    "\n",
    "        self.idx = -1\n",
    "\n",
    "    def _create_schedule(self, segments, iterations):\n",
    "        '''\n",
    "        Creates a schedule given a function, behaviour and size\n",
    "        '''\n",
    "        stages = [cos_annealing(start, end, n) for ((start, end), n) in zip(segments, iterations)]\n",
    "        return np.concatenate(stages)\n",
    "\n",
    "    def step(self):\n",
    "        self.idx += 1\n",
    "        return self.lr_schedule[self.idx], self.mom_schedule[self.idx]\n",
    "    \n",
    "def one_cycle_train(n_epochs, train_dl, valid_dl, model, max_lr=.01, wd=0, alpha=1./ 3,\n",
    "          save_path=None, unfreeze_during_loop:tuple=None):\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "\n",
    "    best_loss = np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    policy = TrainingPolicy(n_epochs=n_epochs, dl=train_dl, max_lr=max_lr)\n",
    "    optimizer = OptimizerWrapper(model, policy, wd=wd, alpha=alpha)\n",
    "\n",
    "    for epoch in tqdm_notebook(range(n_epochs), ):\n",
    "        model.train()\n",
    "        agg_div = 0\n",
    "        agg_loss = 0\n",
    "        train_dl.set_random_choices()\n",
    "        for x, y in tqdm_notebook(train_dl, leave=False):\n",
    "\n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "\n",
    "            out = model(x).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            agg_loss += batch*loss.item()\n",
    "            agg_div += batch\n",
    "            cnt += 1\n",
    "\n",
    "\n",
    "        val_loss, measure, _ = validate_binary(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - train loss {agg_loss/agg_div:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if save_path and val_loss < best_loss:\n",
    "            save_model(model, save_path)\n",
    "            best_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No transfer learning (done in previous experiment)\n",
    "* CNN as feature extractor.\n",
    "* Fine-tune all CNN at once, equal learning rates.\n",
    "* Gradual unfreezing with differential learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a653fee21742c7bbe43646ed055f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af07c7c80434c42a2fbda729649720a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.1691 -  val loss 0.1617 AUC 0.6390\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c346b3d917ae4866bd2704f992b97e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-927c7b26e19b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRETRAINED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mone_cycle_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfreeze_during_loop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgradual_unfreezing\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-34911279cead>\u001b[0m in \u001b[0;36mone_cycle_train\u001b[0;34m(n_epochs, train_dl, valid_dl, model, max_lr, wd, alpha, save_path, unfreeze_during_loop)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msecond_unfreeze\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/practicum/DL-Medical-Physics/architectures.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveAvgPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DenseLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CNN as feature extractor\n",
    "freeze = True\n",
    "gradual_unfreezing = False\n",
    "\n",
    "train_dl = DataBatches(sample_train_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS,\n",
    "                       shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "model = DenseNet121(1, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "save_path = None\n",
    "one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fine-tune all CNN at once, equal learning rates\n",
    "freeze = False\n",
    "gradual_unfreezing = False\n",
    "\n",
    "train_dl = DataBatches(sample_train_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS,\n",
    "                       shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "model = DenseNet121(1, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "save_path = None\n",
    "one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradual unfreezing with differential learning rates\n",
    "freeze = True\n",
    "gradual_unfreezing = True\n",
    "\n",
    "train_dl = DataBatches(sample_train_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS,\n",
    "                       shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "model = DenseNet121(1, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "save_path = None\n",
    "one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1./3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_model(model, save_pathc)\n",
    "test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms = TRANSFORMATIONS, \n",
    "                      shuffle = False, data=DATA, batch_size = BATCH_SIZE, normalize=PRETRAINED)\n",
    "TTA_multilabel(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample range: Writing script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the different combinations on a script. Observe that we have constructed the training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pneumonia.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pneumonia.py\n",
    "\n",
    "import sys; sys.path.append(\"/data/miguel/practicum/DL-Medical-Physics\")\n",
    "\n",
    "from core import *\n",
    "from data_manipulation import DataBatches, RandomRotation, Flip, RandomCrop, balance_obs, multi_label_2_binary\n",
    "from utils import save_model, load_model, lr_loss_plot\n",
    "from architectures import DenseNet121\n",
    "from train_functions import get_optimizer, FinderPolicy, OptimizerWrapper, validate_binary, lr_finder, TTA_binary\n",
    "import json\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "TRANSFORMATIONS = [RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=8)]\n",
    "DATA = 'Pneumonia'\n",
    "\n",
    "idx2tgt = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "tgt2idx = {disease: i for i, disease in enumerate(idx2tgt)}\n",
    "\n",
    "SAMPLE_AMOUNTS = [50,100,200,400,600,800,1000,1200,1400,1600,1800,2000]\n",
    "\n",
    "BASE_PATH = Path('/data/miguel/practicum/')\n",
    "PATH = BASE_PATH/'data'\n",
    "SAVE_DIRECTORY = BASE_PATH/'DL-Medical-Physics/transfer_learning_methods/models'\n",
    "SAVE_DATA = BASE_PATH/'DL-Medical-Physics/transfer_learning_methods/results'\n",
    "IMG_FOLDER = PATH/'ChestXRay-250'\n",
    "PRETRAINED = True # Imagenet\n",
    "\n",
    "\n",
    "def cos_annealing(start_lr, end_lr, n_iterations):\n",
    "    i = np.arange(n_iterations)\n",
    "    c_i = 1 + np.cos(i * np.pi / n_iterations)\n",
    "    return end_lr + (start_lr - end_lr) / 2 * c_i\n",
    "\n",
    "class TrainingPolicy:\n",
    "    '''Cretes the lr and momentum policy'''\n",
    "\n",
    "    def __init__(self, n_epochs, dl, max_lr, pctg=.3, moms=(.95, .85),\n",
    "                 delta=1e-4, div_factor=25.):\n",
    "        \n",
    "        total_iterations = n_epochs * len(dl)\n",
    "\n",
    "        iter1 = int(total_iterations * pctg)\n",
    "        iter2 = total_iterations - int(total_iterations * pctg)\n",
    "        iterations = (iter1, iter2)\n",
    "\n",
    "        min_start = max_lr / div_factor\n",
    "        min_end = min_start * delta\n",
    "\n",
    "        lr_segments = ((min_start, max_lr), (max_lr, min_end))\n",
    "        mom_segments = (moms, (moms[1], moms[0]))\n",
    "\n",
    "        self.lr_schedule = self._create_schedule(lr_segments, iterations)\n",
    "        self.mom_schedule = self._create_schedule(mom_segments, iterations)\n",
    "\n",
    "        self.idx = -1\n",
    "\n",
    "    def _create_schedule(self, segments, iterations):\n",
    "        '''\n",
    "        Creates a schedule given a function, behaviour and size\n",
    "        '''\n",
    "        stages = [cos_annealing(start, end, n) for ((start, end), n) in zip(segments, iterations)]\n",
    "        return np.concatenate(stages)\n",
    "\n",
    "    def step(self):\n",
    "        self.idx += 1\n",
    "        return self.lr_schedule[self.idx], self.mom_schedule[self.idx]\n",
    "    \n",
    "def one_cycle_train(n_epochs, train_dl, valid_dl, model, max_lr=.01, wd=0, alpha=1./ 3,\n",
    "          save_path=None, unfreeze_during_loop:tuple=None):\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "\n",
    "    best_loss = np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    policy = TrainingPolicy(n_epochs=n_epochs, dl=train_dl, max_lr=max_lr)\n",
    "    optimizer = OptimizerWrapper(model, policy, wd=wd, alpha=alpha)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        agg_div = 0\n",
    "        agg_loss = 0\n",
    "        train_dl.set_random_choices()\n",
    "        for x, y in train_dl:\n",
    "\n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "\n",
    "            out = model(x).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            agg_loss += batch*loss.item()\n",
    "            agg_div += batch\n",
    "            cnt += 1\n",
    "\n",
    "\n",
    "        val_loss, measure, _ = validate_binary(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - train loss {agg_loss/agg_div:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if save_path and val_loss < best_loss:\n",
    "            save_model(model, save_path)\n",
    "            best_loss = val_loss\n",
    "\n",
    "# Training            \n",
    "train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "\n",
    "train_df = multi_label_2_binary(train_df, tgt2idx['Pneumonia'])\n",
    "\n",
    "valid_df = multi_label_2_binary(valid_df, tgt2idx['Pneumonia'])\n",
    "valid_df = balance_obs(valid_df, amt=2*len(valid_df[valid_df['Label']==1]))\n",
    "\n",
    "valid_dl = DataBatches(valid_df,img_folder_path=IMG_FOLDER,transforms=False, \n",
    "                       shuffle=False, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "train_df = train_df.sample(frac=1)\n",
    "\n",
    "for N in SAMPLE_AMOUNTS:\n",
    "\n",
    "    df = balance_obs(train_df, amt=N)\n",
    "\n",
    "    train_dl = DataBatches(df, img_folder_path=IMG_FOLDER, transforms=TRANSFORMATIONS, \n",
    "                           shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "    freeze = True\n",
    "    gradual_unfreezing = False    \n",
    "\n",
    "    model = DenseNet121(1, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "\n",
    "    save_path = SAVE_DIRECTORY/f\"pneumonia-feature-extractor-{N}.pth\"\n",
    "\n",
    "    one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=save_path, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)\n",
    "\n",
    "    freeze = False\n",
    "    gradual_unfreezing = False\n",
    "    \n",
    "    model = DenseNet121(1, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "\n",
    "    save_path = SAVE_DIRECTORY/f\"pneumonia-fine-tune-all-{N}.pth\"\n",
    "    \n",
    "    one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=save_path, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)\n",
    "    \n",
    "    freeze = True\n",
    "    gradual_unfreezing = True\n",
    "    \n",
    "    model = DenseNet121(1, pretrained=PRETRAINED, freeze=freeze).cuda()\n",
    "\n",
    "    save_path = SAVE_DIRECTORY/f\"pneumonia-grad-unfr-diff-lr-{N}.pth\"\n",
    "    \n",
    "    one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=save_path, unfreeze_during_loop=(.1, .2) if gradual_unfreezing else None, alpha=1)\n",
    "    \n",
    "# Evaluation\n",
    "\n",
    "test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "feature_extractor = {\n",
    "    'losses':[],\n",
    "    'aucs':[]\n",
    "}\n",
    "fine_tune_all = {\n",
    "    'losses':[],\n",
    "    'aucs':[]\n",
    "}\n",
    "grad_unfr_diff_lr = {\n",
    "    'losses':[],\n",
    "    'aucs':[]\n",
    "}\n",
    "\n",
    "test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms=TRANSFORMATIONS, \n",
    "                      shuffle=False, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "for i, N in enumerate(SAMPLE_AMOUNTS):\n",
    "\n",
    "    model = DenseNet121(1, pretrained=PRETRAINED, freeze=FREEZE).cuda()\n",
    "\n",
    "    load_path = SAVE_DIRECTORY/f\"pneumonia-feature-extractor-{N}.pth\"\n",
    "\n",
    "    load_model(model, load_path)\n",
    "\n",
    "    loss, mean_auc, _ = TTA_binary(model, test_dl, ndl=4)\n",
    "\n",
    "    feature_extractor['losses'].append(loss)\n",
    "    feature_extractor['aucs'].append(mean_auc)\n",
    "\n",
    "    load_path = SAVE_DIRECTORY/f\"pneumonia-fine-tune-all-{N}.pth\"\n",
    "\n",
    "    load_model(model, load_path)\n",
    "\n",
    "    loss, mean_auc, _ = TTA_binary(model, test_dl, ndl=4)\n",
    "\n",
    "    fine_tune_all['losses'].append(loss)\n",
    "    fine_tune_all['aucs'].append(mean_auc)\n",
    "    \n",
    "    save_path = SAVE_DIRECTORY/f\"pneumonia-grad-unfr-diff-lr-training-{N}.pth\"\n",
    "\n",
    "    load_model(model, load_path)\n",
    "\n",
    "    loss, mean_auc, _ = TTA_binary(model, test_dl, ndl=4)\n",
    "\n",
    "    grad_unfr_diff_lr['losses'].append(loss)\n",
    "    grad_unfr_diff_lr['aucs'].append(mean_auc)\n",
    "\n",
    "feature_extractor = json.dumps(feature_extractor)\n",
    "with open('results/pneumonia_feature_extractor.json', 'w') as f:\n",
    "    f.write(feature_extractor)\n",
    "\n",
    "fine_tune_all = json.dumps(fine_tune_all)\n",
    "with open('results/pneumonia_fine_tune_all.json', 'w') as f:\n",
    "    f.write(fine_tune_all)\n",
    "    \n",
    "grad_unfr_diff_lr = json.dumps(grad_unfr_diff_lr)\n",
    "with open('results/pneumonia_grad_unfr_diff_lr.json', 'w') as f:\n",
    "    f.write(grad_unfr_diff_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
