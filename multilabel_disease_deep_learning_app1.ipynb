{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from core import * # basic imports\n",
    "from data_manipulation import DataBatches, RandomRotation, Flip, RandomCrop\n",
    "from utils import save_model, load_model, lr_loss_plot\n",
    "from architectures import DenseNet121\n",
    "from train_functions import get_optimizer, FinderPolicy, OptimizerWrapper, validate_multilabel\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained = True\n",
    "batch_size = 16\n",
    "epochs = 8\n",
    "freeze = False\n",
    "\n",
    "random_states = [42]\n",
    "\n",
    "PATH = Path('../data')\n",
    "SAVE_DIRECTORY = Path('../latest_models/14diseases-app1')\n",
    "SAVE_PLOT = Path('../latest_plots/14diseases-app1')\n",
    "\n",
    "img_folder_path = PATH/'ChestXRay-250'\n",
    "data = '14diseases'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Batch creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=img_folder_path,\n",
    "                               transforms=True, shuffle=True, data=data,\n",
    "                               batch_size=batch_size, normalize=pretrained)\n",
    "\n",
    "valid_dl = DataBatches(valid_df,img_folder_path=img_folder_path,\n",
    "                     transforms = False, shuffle = False, data= data,\n",
    "                     batch_size = batch_size, normalize=pretrained)\n",
    "\n",
    "test_dl = DataBatches(test_df,img_folder_path=img_folder_path,\n",
    "                  transforms = True, shuffle = False, data=data,\n",
    "                  batch_size = batch_size, normalize=pretrained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_dl.set_random_choices()\n",
    "\n",
    "# x,y = next(iter(train_dl))\n",
    "# x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DenseNet121(14, pretrained=pretrained, freeze=False).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same learning rate finder but specifying `alpha=1` to don't use differential learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LR finder loop\n",
    "def lr_finder(model, n_epochs, train_dl, min_lr=1e-7, max_lr=10, save_path=None,\n",
    "              alpha=1./3, early_stopping=200):\n",
    "\n",
    "    if save_path: save_model(model, save_path)\n",
    "    model.train()\n",
    "    \n",
    "    policy = FinderPolicy(n_epochs=n_epochs, dl=train_dl, min_lr=min_lr, max_lr=max_lr)\n",
    "    optimizer = OptimizerWrapper(model, policy, alpha=alpha)\n",
    "\n",
    "    lrs = optimizer.policy.lr_schedule\n",
    "    \n",
    "    losses = []\n",
    "    cnt = 0\n",
    "\n",
    "    for _ in tqdm_notebook(range(n_epochs)):\n",
    "        train_dl.set_random_choices()\n",
    "        for it, (x, y) in enumerate(tqdm_notebook(train_dl)):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if it%200 == 199: lr_loss_plot(lrs, losses)\n",
    "            if cnt==early_stopping: return lrs[:cnt], losses\n",
    "            cnt +=1\n",
    "\n",
    "    if save_path: load_model(model, p)\n",
    "\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06474d576d144f75bed391f18f469f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e26f41df70b485e82def9ddc7506a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEaCAYAAADqqhd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DenseNet121(14, pretrained=pretrained, freeze=False).cuda()\n",
    "lrs, losses  = lr_finder(model, 1, train_dl, min_lr=1e-4, max_lr=1e-1, alpha=1, early_stopping=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train function for **regular policy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epochs, train_dl, valid_dl, model, save_path=None,\n",
    "          min_lr=1e-6, max_lr=0.001, epsilon=.01, unfreeze_during_loop:tuple=None):\n",
    "    lr = max_lr\n",
    "    prev_loss, min_loss = np.inf, np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "        \n",
    "    \n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "        model.train()\n",
    "        train_dl.set_random_choices()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        optim = get_optimizer(model, lr=lr, wd=0)\n",
    "        for x, y in tqdm_notebook(train_dl, leave=False):\n",
    "            \n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total += batch\n",
    "            sum_loss += batch * (loss.item())\n",
    "            \n",
    "            cnt += 1\n",
    "                \n",
    "        val_loss, measure, _ = validate_multilabel(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - lr {lr:.7f} train loss {sum_loss/total:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if val_loss - prev_loss > epsilon:\n",
    "            lr = lr / 10.0\n",
    "        if val_loss < min_loss:\n",
    "            if save_path: save_model(model, save_path)\n",
    "            min_loss = val_loss\n",
    "        prev_loss = val_loss\n",
    "        if lr < min_lr:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a5e42cac164401ba3a283934021be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a102544d963149e2824b584c8520c717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - lr 0.0000010 train loss 0.4021 -  val loss 0.2240 AUC 0.6184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980794155bfa49f8a84d84c818249aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - lr 0.0000010 train loss 0.1765 -  val loss 0.1603 AUC 0.6911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f45f21dcd604f34aa5bec5644f8b575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - lr 0.0000010 train loss 0.1518 -  val loss 0.1544 AUC 0.7178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917c0f1cc144478a8b12929d02d1515d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - lr 0.0000010 train loss 0.1480 -  val loss 0.1520 AUC 0.7329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbffb80752b6413dbcd1710e6db05635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 5 - lr 0.0000010 train loss 0.1461 -  val loss 0.1507 AUC 0.7428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121d3f4c4feb46f08f4edbb217109cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 6 - lr 0.0000010 train loss 0.1446 -  val loss 0.1493 AUC 0.7504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd60ec3aff8a45078cb136f14c8fbaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 7 - lr 0.0000010 train loss 0.1433 -  val loss 0.1485 AUC 0.7573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32695a393fd0427c81b9cdfcfb02975e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 8 - lr 0.0000010 train loss 0.1425 -  val loss 0.1478 AUC 0.7604\n"
     ]
    }
   ],
   "source": [
    "# tiny version\n",
    "\n",
    "transforms=[RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=8)]\n",
    "train_dl = DataBatches(train_df, img_folder_path=img_folder_path,\n",
    "                               transforms=transforms, shuffle=True, data=data,\n",
    "                               batch_size=batch_size, normalize=pretrained)\n",
    "\n",
    "model = DenseNet121(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "\n",
    "train(epochs, train_dl, valid_dl, model, max_lr=.001, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bed1429f9f4883aa6d8a273665a4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9786e882d21645f596d8b6b09ac257cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.3406 -  val loss 0.1666 AUC 0.6493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d2406b1f9f4b8d85445a9be40e78a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - train loss 0.1556 -  val loss 0.1735 AUC 0.6702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ff7b0306924b71abccad1d972227a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - train loss 0.1525 -  val loss 0.1693 AUC 0.6736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b31632c62e47e1910f6b2593285fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - train loss 0.1434 -  val loss 0.1644 AUC 0.6954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beea534b8c3d4a5cbedc8351119b53c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 5 - train loss 0.1352 -  val loss 0.1689 AUC 0.7035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6a7aa1a21b4e2593975ecdd48ffc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 6 - train loss 0.1261 -  val loss 0.1664 AUC 0.6972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842833ec85df455988cf9d4474b1a96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 7 - train loss 0.1152 -  val loss 0.1659 AUC 0.7107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c540b94fbc4336926212945a8900d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 8 - train loss 0.1098 -  val loss 0.1655 AUC 0.7091\n"
     ]
    }
   ],
   "source": [
    "# tiny version\n",
    "\n",
    "class random_rotation_v2:\n",
    "    \"\"\" Rotates an image by deg degrees\n",
    "\n",
    "    Args: -\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __call__(self, im, deg,\n",
    "                 mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
    "        r, c, *_ = im.shape\n",
    "        M = cv2.getRotationMatrix2D((c / 2, r / 2), deg, 1)\n",
    "        return cv2.warpAffine(im, M, (c, r), borderMode=mode,\n",
    "                              flags=cv2.WARP_FILL_OUTLIERS + interpolation)\n",
    "\n",
    "    def options(self, x_shape):\n",
    "        \"\"\"Specify the random arguments to be generated every epoch.\n",
    "        Images must be have same dimensions !\n",
    "        \"\"\"\n",
    "        return {\"deg\": -1}\n",
    "\n",
    "    def set_random_choices(self, N, x_shape):\n",
    "        return {k: np.random.choice([-90,0,90], size=N, replace=True)  for k, v in self.options(x_shape).items()}\n",
    "\n",
    "\n",
    "N  = 2_000\n",
    "tiny_df = train_df[:N]\n",
    "transforms=[random_rotation_v2(), random_rotation(arc_width=20), flip(), random_crop(r_pix=8)]\n",
    "tiny_dl = DataBatches(tiny_df, img_folder_path=img_folder_path,\n",
    "                               transforms=transforms, shuffle=True, data=data,\n",
    "                               batch_size=batch_size, normalize=pretrained)\n",
    "\n",
    "model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "\n",
    "train(epochs, tiny_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6fc538a7ff4111bcfa3b49bc2695af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4cf9ecb2a245c196d435a6d235b2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.1539 -  val loss 0.1467 AUC 0.7846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e701e04fe7a24bfdbc84a9d185a55420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - train loss 0.1402 -  val loss 0.1474 AUC 0.7900\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60c29511a1546cf975ab06090118632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - train loss 0.1379 -  val loss 0.1452 AUC 0.7984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fefb90c210c4b09ae5e9884551765a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - train loss 0.1339 -  val loss 0.1426 AUC 0.8193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e6c6b8297242bb9428e8d700d0074e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Whole dataset\n",
    "\n",
    "transforms=[random_rotation(arc_width=20), flip(), random_crop(r_pix=8)]\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=img_folder_path,transforms=transforms,\n",
    "                       shuffle=True, data=data, batch_size=batch_size, normalize=pretrained)\n",
    "\n",
    "model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "\n",
    "train(epochs, train_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dl = DataBatches(test_df,img_folder_path=img_folder_path, transforms = True, \n",
    "                      shuffle = False, data=data, batch_size = batch_size, normalize=pretrained)\n",
    "TTA_multilabel(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1)\n",
    "\n",
    "for N in [50, 100, 5_000, 10_000, 20_000, 35_000, 50_000, 60_000, 77_880]:\n",
    "    \n",
    "    sampled_train_df = train_df[:N]\n",
    "    \n",
    "    train_dl = DataBatches(train_df, img_folder_path=img_folder_path,\n",
    "                           transforms=True, shuffle=True, data=data,\n",
    "                           batch_size=batch_size, half=False, normalize=pretrained)\n",
    "    \n",
    "    model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "    save_path = SAVE_DIRECTORY/f\"{pretrained}-{N}.pth\"\n",
    "    # save_path = SAVE_DIRECTORY / f\"{pretrained}-{N}-{random_state}-unfreezing.pth\"\n",
    "    train(epochs, train_dl, valid_dl, model, max_lr=.001, save_path=save_path,unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20191780040408833,\n",
       " 0.8164163548894331,\n",
       " [0.7777638937179043,\n",
       "  0.8882716944725164,\n",
       "  0.8331421478637311,\n",
       "  0.6839344107757633,\n",
       "  0.8366145269199207,\n",
       "  0.7661666072832656,\n",
       "  0.7252368098300768,\n",
       "  0.8640024568362074,\n",
       "  0.752993899915239,\n",
       "  0.8507316063175169,\n",
       "  0.9233914222053733,\n",
       "  0.8275160380939851,\n",
       "  0.7879706132917902,\n",
       "  0.9120928409287741])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl = DataBatches(test_df,img_folder_path=img_folder_path,\n",
    "                  transforms = False, shuffle = False, data=data,\n",
    "                  batch_size = batch_size, normalize=pretrained)\n",
    "validate(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.2021 and auc 0.8210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20208021653882324, 0.8209861720227334)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl = DataBatches(test_df,img_folder_path=img_folder_path,\n",
    "                  transforms = True, shuffle = False, data=data,\n",
    "                  batch_size = batch_size, normalize=pretrained)\n",
    "TTA_test_metrics_chest(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d59bdd3bd748b7a5b5be93075f3db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e318da8cf059411bab4fb4570493ec7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.1535 -  val loss 0.1460 AUC 0.7735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33d6b526dbc4a52953733c89ed0d7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - train loss 0.1403 -  val loss 0.1490 AUC 0.7919\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958ad7d2cc65463190076328affb91a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - train loss 0.1379 -  val loss 0.1473 AUC 0.8027\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4460556e0dde4ad492b31361ec16b139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - train loss 0.1337 -  val loss 0.1427 AUC 0.8155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f299f3e060f54abbb40fe274b28e7ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 5 - train loss 0.1295 -  val loss 0.1388 AUC 0.8338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72631ddb5d34cde93fdbd38cf1358ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 6 - train loss 0.1251 -  val loss 0.1369 AUC 0.8358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f662b10fdb2849b18f2ed4e0a0eed2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 7 - train loss 0.1200 -  val loss 0.1369 AUC 0.8411\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83d2495e4394ad7bb0928883b010729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 38728 is out of bounds for axis 0 with size 38728",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-95249fe8f649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# save_path = SAVE_DIRECTORY / f\"{pretrained}-{N}-{random_state}-unfreezing.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munfreeze_during_loop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfreeze\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-a357c34d05eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, train_dl, valid_dl, model, div_factor, max_lr, wd, alpha, save_path, unfreeze_during_loop)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a357c34d05eb>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a357c34d05eb>\u001b[0m in \u001b[0;36m_update_optimizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mlr_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lr_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mparam_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a357c34d05eb>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmom_schedule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 38728 is out of bounds for axis 0 with size 38728"
     ]
    }
   ],
   "source": [
    "model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "save_path = SAVE_DIRECTORY/f\"{pretrained}-77800.pth\"\n",
    "# save_path = SAVE_DIRECTORY / f\"{pretrained}-{N}-{random_state}-unfreezing.pth\"\n",
    "train(epochs, train_dl, valid_dl, model, max_lr=.001, save_path=save_path,unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the different combinations on a script. Observe that we have constructed the training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting disease14_aprx1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile disease14_aprx1.py\n",
    "\n",
    "from core import * # basic imports\n",
    "from data_manipulation import DataBatches, RandomRotation, Flip, RandomCrop\n",
    "from utils import save_model, load_model, lr_loss_plot\n",
    "from architectures import DenseNet121\n",
    "from train_functions import get_optimizer, FinderPolicy, OptimizerWrapper, validate_multilabel\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "transforms=[RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=8)]\n",
    "data = '14diseases'\n",
    "\n",
    "methods = [(False, False, False),\n",
    "           (True, True, False),\n",
    "           (True, False, False),\n",
    "           (True, True, True),\n",
    "           ('MURA', True, False),\n",
    "           ('MURA', False, False),\n",
    "           ('MURA', True, True)] # pretrained / freeze first blocks / prog_unfreezing\n",
    "random_states = range(10)\n",
    "n_samples = [50,100,200,400,600,800,1000,1200,1400,1600,1800, 2000]\n",
    "\n",
    "PATH = Path('../data')\n",
    "SAVE_DIRECTORY = Path('../latest_models/14diseases-app1')\n",
    "SAVE_DATA = Path('../latest_data/14diseases-app1')   \n",
    "img_folder_path = PATH/'ChestXRay-250'\n",
    "\n",
    "\n",
    "def train(epochs, train_dl, valid_dl, model, save_path=None,min_lr=1e-6,\n",
    "          max_lr=0.001, epsilon=.01, unfreeze_during_loop:tuple=None):\n",
    "    \n",
    "    lr = max_lr\n",
    "    prev_loss, min_loss = np.inf, np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_dl.set_random_choices()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        optim = get_optimizer(model, lr=lr, wd=0)\n",
    "        for x, y in train_dl:\n",
    "            \n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total += batch\n",
    "            sum_loss += batch * (loss.item())\n",
    "            \n",
    "            cnt += 1\n",
    "                \n",
    "        val_loss, measure, _ = validate_multilabel(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - lr {lr:.7f} train loss {sum_loss/total:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if val_loss - prev_loss > epsilon:\n",
    "            lr = lr / 10.0\n",
    "        if val_loss < min_loss:\n",
    "            if save_path: save_model(model, save_path)\n",
    "            min_loss = val_loss\n",
    "        \n",
    "        prev_loss = val_loss\n",
    "        if lr < min_lr:\n",
    "            break\n",
    "\n",
    "# Training            \n",
    "\n",
    "train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "\n",
    "\n",
    "for pretrained, freeze, grad_unfreez in methods:\n",
    "    \n",
    "    valid_dl = DataBatches(valid_df,img_folder_path=img_folder_path,\n",
    "                     transforms = False, shuffle = False, data= data,\n",
    "                     batch_size = batch_size, normalize=pretrained)\n",
    "\n",
    "    for rs in random_states:\n",
    "\n",
    "        train_df = train_df.sample(frac=1)\n",
    "\n",
    "        for N in n_samples:\n",
    "\n",
    "            df = train_df[:N]\n",
    "\n",
    "            train_dl = DataBatches(df, img_folder_path=img_folder_path, transforms=transforms, shuffle=True, data=data,\n",
    "                                   batch_size=batch_size, normalize=pretrained)\n",
    "\n",
    "            model = DenseNet121(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "\n",
    "            save_path = SAVE_DIRECTORY/f\"{pretrained}-{freeze}-{grad_unfreez}-{N}-{rs}.pth\"\n",
    "\n",
    "            train(epochs, train_dl, valid_dl, model, max_lr=.001, save_path=save_path, unfreeze_during_loop=(.1, .2) if grad_unfreez else None)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "for pretrained, freeze, grad_unfreeze in methods:\n",
    "    \n",
    "    test_dl = DataBatches(test_df,img_folder_path=img_folder_path,\n",
    "                  transforms = True, shuffle = False, data=data,\n",
    "                  batch_size = batch_size, normalize=pretrained)\n",
    "    \n",
    "    losses = [[] for _ in n_samples]\n",
    "    aucs = [[] for _ in n_samples]\n",
    "    \n",
    "    loss_path = SAVE_DATA/f\"losses_{pretrained}_{freeze}_{grad_unfreeze}\"\n",
    "    aucs_path = SAVE_DATA/f\"aucs_{pretrained}_{freeze}_{grad_unfreeze}\"\n",
    "    \n",
    "    for i, N in enumerate(n_samples):\n",
    "        \n",
    "        for rs in random_states:\n",
    "            \n",
    "            model = DenseNet121(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "\n",
    "            load_path = SAVE_DIRECTORY/f\"{pretrained}-{freeze}-{grad_unfreeze}-{N}-{rs}.pth\"\n",
    "            \n",
    "            load_model(model, load_path)\n",
    "            \n",
    "            loss, mean_auc, _ = TTA_multilabel(model, test_dl, ndl=4)\n",
    "            \n",
    "            losses[i].append(loss)\n",
    "            aucs[i].append(mean_auc)\n",
    "    \n",
    "    losses = np.array(losses)\n",
    "    aucs = np.array(aucs)\n",
    "    \n",
    "    numpy.save(loss_path, losses)\n",
    "    numpy.save(aucs_path, aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
