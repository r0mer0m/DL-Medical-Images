{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "# from __core__ import *\n",
    "# from __utils__ import *\n",
    "\n",
    "# from __models__ import *\n",
    "# from __train__ import *\n",
    "# from functools  import partial\n",
    "# import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from pathlib import Path\n",
    "from __dataBatches__ import *\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MURA Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained = True\n",
    "batch_size = 16\n",
    "epochs = 8\n",
    "freeze = False\n",
    "\n",
    "random_states = [42]\n",
    "\n",
    "PATH = Path('../data')\n",
    "SAVE_DIRECTORY = Path('../latest_models/chest')\n",
    "SAVE_PLOT = Path('../latest_plots/chest')\n",
    "\n",
    "img_folder_path = PATH/'ChestXRay-250'\n",
    "data = 'chest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Batch creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=img_folder_path,\n",
    "                               transforms=True, shuffle=True, data=data,\n",
    "                               batch_size=batch_size, normalize=pretrained)\n",
    "\n",
    "valid_dl = DataBatches(valid_df,img_folder_path=img_folder_path,\n",
    "                     transforms = False, shuffle = False, data= data,\n",
    "                     batch_size = batch_size, normalize=pretrained)\n",
    "\n",
    "test_dl = DataBatches(test_df,img_folder_path=img_folder_path,\n",
    "                  transforms = True, shuffle = False, data=data,\n",
    "                  batch_size = batch_size, normalize=pretrained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dl.set_random_choices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 234, 234]), torch.Size([16, 14]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 234, 234]), torch.Size([16, 14]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "\n",
    "\n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n",
    "\n",
    "\n",
    "def get_top_layers(pretrained):\n",
    "    '''Return a list of the top groups of paramteres. \n",
    "    Handles cases when:\n",
    "    > Model structure is in sequential groups (MURA)\n",
    "    > Model structure is the default from densenet121 architecture\n",
    "    '''\n",
    "    if pretrained == 'MURA':\n",
    "        top = DenseNet(1, False)\n",
    "        load_model(top, '../latest_models/mura_2.pth')\n",
    "        out = list([group.children() for group in top.groups[:2]])\n",
    "    elif pretrained in (True, False):\n",
    "        top_model = models.densenet121(pretrained=pretrained)\n",
    "        top_layers = list(top_model.children())[0]\n",
    "        out = [top_layers[:7], top_layers[7:]]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid pretrained value\")\n",
    "        \n",
    "    return out\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    '''\n",
    "    DenseNet121 with quick iterations on:\n",
    "     > arbitrary finite out_size.\n",
    "     > pre-trained model between ImageNet and the medical image data-set MURA (all but last layer).\n",
    "     > half float precision (16)\n",
    "     > freeze layers\n",
    "    '''\n",
    "\n",
    "    def __init__(self, out_size: int = 14, pretrained: bool = False, freeze: str = False):\n",
    "        '''\n",
    "\n",
    "        :param out_size: (int) output size\n",
    "        :param pretrained: (bool/str) Kind of pre-train: Supports  'MURA', True and False.\n",
    "        :param freeze: (bool) freeze all layers but last one.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        top_layers_groups = get_top_layers(pretrained)\n",
    "\n",
    "        self.groups = nn.ModuleList([nn.Sequential(*group) for group in top_layers_groups])\n",
    "        self.groups.append(nn.Linear(1024, out_size))\n",
    "\n",
    "        if freeze: self.freeze([0, 1])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for group in self.groups[:-1]:\n",
    "            x = group(x)\n",
    "        x = F.relu(x)\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.groups[-1](x)\n",
    "        return x\n",
    "\n",
    "    def freeze(self, group_idxs: (list,int,tuple)):\n",
    "        if not isinstance(group_idxs, (list, tuple)): group_idxs = [group_idxs]\n",
    "        for group_idx in group_idxs:\n",
    "            group = self.groups[group_idx]\n",
    "            parameters = filter(lambda x: x.requires_grad, group.parameters())\n",
    "            for p in parameters:\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def unfreeze(self, group_idx: int):\n",
    "        if group_idx not in [0, 1, 2]: raise ValueError('group_idx must be between 0 and 2')\n",
    "        group = self.groups[group_idx]\n",
    "        parameters = filter(lambda x: hasattr(x, 'requires_grad'), group.parameters())\n",
    "        for p in parameters: p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = DenseNet(14, pretrained=pretrained, freeze=False).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(2,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Annealings ###\n",
    "\n",
    "def exp_annealing(start_lr, end_lr, n):\n",
    "    ptg = np.linspace(0, 1, n)\n",
    "    return start_lr * (end_lr / start_lr) ** ptg\n",
    "\n",
    "def cos_annealing(start_lr, end_lr, n_iterations):\n",
    "    i = np.arange(n_iterations)\n",
    "    c_i = 1 + np.cos(i * np.pi / n_iterations)\n",
    "    return end_lr + (start_lr - end_lr) / 2 * c_i\n",
    "\n",
    "### Diff lr ###\n",
    "\n",
    "def diff_range(val, alpha=1.3):\n",
    "    return [val*alpha**i for i in range(2,-1,-1)]\n",
    "\n",
    "##### LR finder : Plicy, Optimizer and \n",
    "class FinderPolicy:\n",
    "\n",
    "    def __init__(self, n_epochs, dl, min_lr=1e-7, max_lr=10):\n",
    "        '''\n",
    "        Implements exponential annealing policy from min_lr to max_lr\n",
    "        '''\n",
    "        total_iterations = n_epochs * len(dl)\n",
    "        self.lr_schedule = exp_annealing(min_lr, max_lr, total_iterations)\n",
    "        self.mom = .9 # constant momentum policy with default value\n",
    "        self.idx = -1\n",
    "\n",
    "    def step(self):\n",
    "        self.idx = self.idx + 1\n",
    "        return self.lr_schedule[self.idx], self.mom\n",
    "    \n",
    "    \n",
    "class TrainingPolicy:\n",
    "    '''Cretes the lr and momentum policy'''\n",
    "    \n",
    "    def __init__(self, n_epochs, dl, max_lr, pctg=.3, moms=(.95, .85),\n",
    "                 delta=1e-4, div_factor=25.):\n",
    "\n",
    "        total_iterations = n_epochs * len(dl)\n",
    "        \n",
    "        iter1 = int(total_iterations * pctg)\n",
    "        iter2 = total_iterations - int(total_iterations * pctg)\n",
    "        iterations = (iter1, iter2)\n",
    "        \n",
    "        \n",
    "        min_start = max_lr /div_factor\n",
    "        min_end = min_start*delta\n",
    "        \n",
    "        lr_segments = ((min_start, max_lr), (max_lr, min_end))\n",
    "        mom_segments = (moms, (moms[1], moms[0]))\n",
    "\n",
    "        self.lr_schedule = self._create_schedule(lr_segments, iterations)\n",
    "        self.mom_schedule = self._create_schedule(mom_segments, iterations)\n",
    "\n",
    "        self.idx = -1\n",
    "\n",
    "    def _create_schedule(self, segments, iterations):\n",
    "        '''\n",
    "        Creates a schedule given a function, behaviour and size\n",
    "        '''\n",
    "        stages = [cos_annealing(start, end, n) for ((start, end), n) in zip(segments, iterations)]\n",
    "        return np.concatenate(stages)\n",
    "\n",
    "    def step(self):\n",
    "        self.idx += 1\n",
    "        return self.lr_schedule[self.idx], self.mom_schedule[self.idx]\n",
    "        \n",
    "class OptimizerWrapper:\n",
    "    '''Without using the momentum policy'''\n",
    "    \n",
    "    def __init__(self, model, policy, wd=0, alpha=1./ 3):\n",
    "\n",
    "        self.policy = policy # TrainingPolicy(n_epochs=n_epochs, dl=dl, max_lr=max_lr)\n",
    "\n",
    "        self.model = model\n",
    "        self.alpha = alpha\n",
    "        self.wd = wd\n",
    "        \n",
    "        # This assumes the model is defined by groups.\n",
    "        param_groups = [group.parameters() for group in list(self.model.children())[0]]\n",
    "        lr_0 = self.policy.lr_schedule[0]\n",
    "        mom_0 = self.policy.mom_schedule[0] if hasattr(self.policy, 'mom_schedule') else .9\n",
    "        \n",
    "        groups = zip(param_groups, diff_range(lr_0, alpha=alpha), diff_range(mom_0, alpha=1))\n",
    "        \n",
    "        self.optimizer = optim.Adam(\n",
    "            [{'params': p, 'lr': lr, 'mom': (mom,.999)} for p, lr, mom in groups]\n",
    "        )\n",
    "\n",
    "    def _update_optimizer(self):\n",
    "        lr_i, mom_i = self.policy.step()\n",
    "        groups = zip(self.optimizer.param_groups, \n",
    "                     diff_range(lr_i, alpha=self.alpha), \n",
    "                     diff_range(mom_i, alpha=1))\n",
    "        \n",
    "        for param_group, lr, mom in groups:\n",
    "            param_group['lr'] = lr\n",
    "            param_group['mom'] = (mom,.999)\n",
    "        \n",
    "    def _weight_decay(self):\n",
    "        for group in self.optimizer.param_group:\n",
    "                for p in group['params']: p.data.mul_(group['lr'] * self.wd)\n",
    "        \n",
    "    def step(self):\n",
    "        self._update_optimizer()\n",
    "        if self.wd != 0: self._weight_decay()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "# LR finder loop\n",
    "def lr_finder(model, n_epochs, train_dl, min_lr=1e-7, max_lr=10, save_path=None,\n",
    "              mode='exponential', early_stopping=200):\n",
    "\n",
    "    if save_path: save_model(model, save_path)\n",
    "    model.train()\n",
    "    \n",
    "    policy = FinderPolicy(n_epochs=n_epochs, dl=train_dl, min_lr=min_lr, max_lr=max_lr)\n",
    "    optimizer = OptimizerWrapper(model, policy)\n",
    "\n",
    "    lrs = optimizer.policy.lr_schedule\n",
    "    \n",
    "    losses = []\n",
    "    cnt = 0\n",
    "\n",
    "    for _ in tqdm_notebook(range(n_epochs)):\n",
    "        train_dl.set_random_choices()\n",
    "        for it, (x, y) in enumerate(tqdm_notebook(train_dl)):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if it%200 == 199:\n",
    "                plt.plot(lrs[:len(losses)], losses)\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.show()\n",
    "\n",
    "            if cnt==early_stopping: return lrs[:cnt], losses\n",
    "            cnt +=1\n",
    "\n",
    "    if save_path: load_model(model, p)\n",
    "\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_finder(model, n_epochs, train_dl, min_lr=1e-7, max_lr=10, save_path=None,\n",
    "              mode='exponential', early_stopping=200):\n",
    "\n",
    "    if save_path: save_model(model, save_path)\n",
    "\n",
    "    optimizer = FinderOptimizerWrapper(model, n_epochs, train_dl, min_lr=min_lr, max_lr=max_lr, wd=0, mode=mode)\n",
    "\n",
    "    lrs = optimizer.policy.lr_schedule\n",
    "    losses = []\n",
    "    cnt = 0\n",
    "\n",
    "    for _ in tqdm_notebook(range(n_epochs)):\n",
    "        model.train()\n",
    "        train_dl.set_random_choices()\n",
    "        for it, (x, y) in enumerate(tqdm_notebook(train_dl)):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if it%200 == 199:\n",
    "                plt.plot(lrs[:len(losses)], losses)\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.show()\n",
    "\n",
    "            if cnt==early_stopping: return lrs[:cnt], losses\n",
    "            cnt +=1\n",
    "\n",
    "    if save_path: load_model(model, p)\n",
    "\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca25e8182f43488a8702402ae966a29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f43b92f49444936a48bac92f16a397c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEaCAYAAADqqhd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4G6MMRPEg7sxxkyQvwGPhbQSdMxoCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DenseNet(14, pretrained=pretrained, freeze=False).cuda()\n",
    "lrs, losses  = lr_finder(model, 1, train_dl, min_lr=1e-4, max_lr=1e-1, early_stopping=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_AUCs(y, pred):\n",
    "    AUROCs = []\n",
    "    for i in range(N_CLASSES):\n",
    "        auc_i = roc_auc_score(y[:, i].astype(int), pred[:, i])\n",
    "        AUROCs.append(auc_i)\n",
    "    return  np.mean(AUROCs)\n",
    "\n",
    "def ave_auc(probs, ys):\n",
    "    aucs = [roc_auc_score(ys[:,i], probs[:,i]) for i in range(probs.shape[1])]\n",
    "    return np.mean(aucs), aucs   \n",
    "\n",
    "\n",
    "def validate(model, valid_dl):\n",
    "    \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    ys = []\n",
    "    preds = []\n",
    "    \n",
    "    for x, y in valid_dl:\n",
    "        \n",
    "        out = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "        \n",
    "        batch = y.shape[0]\n",
    "        sum_loss += batch * (loss.item())\n",
    "        total += batch\n",
    "        \n",
    "        preds.append( out.detach().cpu().numpy())\n",
    "        ys.append( y.long().cpu().numpy())\n",
    "\n",
    " \n",
    "        \n",
    "    preds = np.vstack(preds)\n",
    "    ys = np.vstack(ys)\n",
    "    mean_auc, aucs = ave_auc(preds, ys)\n",
    "    \n",
    "#     print('\\n'.join([f'{m:.3f}' for m in auc])+'\\n')\n",
    "    \n",
    "    return sum_loss / total, mean_auc, aucs\n",
    "\n",
    "def train(n_epochs, train_dl, valid_dl, model, div_factor=25., max_lr=.01, wd=0, alpha=1./ 3,\n",
    "          save_path=None, unfreeze_during_loop:tuple=None):\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    policy = TrainingPolicy(n_epochs=n_epochs, dl=train_dl, max_lr=max_lr)\n",
    "    optimizer = OptimizerWrapper(model, policy, wd=wd, alpha=alpha)\n",
    "\n",
    "    for epoch in tqdm_notebook(range(n_epochs), ):\n",
    "        model.train()\n",
    "        agg_div = 0\n",
    "        agg_loss = 0\n",
    "        train_dl.set_random_choices()\n",
    "        for i, (x, y) in enumerate(tqdm_notebook(train_dl, leave=False)):\n",
    "\n",
    "            if unfreeze_during_loop:\n",
    "                if i == first_unfreeze: model.unfreeze(1)\n",
    "                if i == second_unfreeze: model.unfreeze(0)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            agg_loss += batch*loss.item()\n",
    "            agg_div += batch\n",
    "\n",
    "\n",
    "        val_loss, measure, _ = validate(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - train loss {agg_loss/agg_div:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if save_path and val_loss < best_loss:\n",
    "            save_model(model, save_path)\n",
    "            best_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac2bdd365144e4287ac7361d2b484d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3f5bc934ee438686bd0630e7a36450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.2881 -  val loss 0.1628 AUC 0.6458\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ec97f39a374bc496d8d966abafb07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - train loss 0.1509 -  val loss 0.1610 AUC 0.6857\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b771be1ec6b448d8f40ebfb0743cb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - train loss 0.1426 -  val loss 0.1681 AUC 0.6922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b257c052e65e48008ce074783c3e9f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - train loss 0.1292 -  val loss 0.1663 AUC 0.7042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5849a1c94d45c69997381ae4af825f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 5 - train loss 0.1141 -  val loss 0.1712 AUC 0.6959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa734cf971284291a33ad9cd1649733b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 6 - train loss 0.0938 -  val loss 0.1743 AUC 0.7089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0cfca00bf341f6b40ab4587163d7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 7 - train loss 0.0746 -  val loss 0.1814 AUC 0.7055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d082f88399140b8801f50838f36eb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 8 - train loss 0.0628 -  val loss 0.1810 AUC 0.7026\n"
     ]
    }
   ],
   "source": [
    "# tiny version\n",
    "\n",
    "N  = 2_000\n",
    "tiny_df = train_df[:N]\n",
    "transforms=[random_rotation(arc_width=20), filp(), random_crop(r_pix=8)]\n",
    "tiny_dl = DataBatches(tiny_df, img_folder_path=img_folder_path,\n",
    "                               transforms=transforms, shuffle=True, data=data,\n",
    "                               batch_size=batch_size, normalize=pretrained)\n",
    "\n",
    "model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "\n",
    "train(epochs, tiny_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bed1429f9f4883aa6d8a273665a4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9786e882d21645f596d8b6b09ac257cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.3406 -  val loss 0.1666 AUC 0.6493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d2406b1f9f4b8d85445a9be40e78a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - train loss 0.1556 -  val loss 0.1735 AUC 0.6702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ff7b0306924b71abccad1d972227a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - train loss 0.1525 -  val loss 0.1693 AUC 0.6736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b31632c62e47e1910f6b2593285fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - train loss 0.1434 -  val loss 0.1644 AUC 0.6954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beea534b8c3d4a5cbedc8351119b53c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 5 - train loss 0.1352 -  val loss 0.1689 AUC 0.7035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6a7aa1a21b4e2593975ecdd48ffc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 6 - train loss 0.1261 -  val loss 0.1664 AUC 0.6972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842833ec85df455988cf9d4474b1a96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 7 - train loss 0.1152 -  val loss 0.1659 AUC 0.7107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c540b94fbc4336926212945a8900d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 8 - train loss 0.1098 -  val loss 0.1655 AUC 0.7091\n"
     ]
    }
   ],
   "source": [
    "# tiny version\n",
    "\n",
    "class random_rotation_v2:\n",
    "    \"\"\" Rotates an image by deg degrees\n",
    "\n",
    "    Args: -\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __call__(self, im, deg,\n",
    "                 mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
    "        r, c, *_ = im.shape\n",
    "        M = cv2.getRotationMatrix2D((c / 2, r / 2), deg, 1)\n",
    "        return cv2.warpAffine(im, M, (c, r), borderMode=mode,\n",
    "                              flags=cv2.WARP_FILL_OUTLIERS + interpolation)\n",
    "\n",
    "    def options(self, x_shape):\n",
    "        \"\"\"Specify the random arguments to be generated every epoch.\n",
    "        Images must be have same dimensions !\n",
    "        \"\"\"\n",
    "        return {\"deg\": -1}\n",
    "\n",
    "    def set_random_choices(self, N, x_shape):\n",
    "        return {k: np.random.choice([-90,0,90], size=N, replace=True)  for k, v in self.options(x_shape).items()}\n",
    "\n",
    "\n",
    "N  = 2_000\n",
    "tiny_df = train_df[:N]\n",
    "transforms=[random_rotation_v2(), random_rotation(arc_width=20), flip(), random_crop(r_pix=8)]\n",
    "tiny_dl = DataBatches(tiny_df, img_folder_path=img_folder_path,\n",
    "                               transforms=transforms, shuffle=True, data=data,\n",
    "                               batch_size=batch_size, normalize=pretrained)\n",
    "\n",
    "model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "\n",
    "train(epochs, tiny_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6fc538a7ff4111bcfa3b49bc2695af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4cf9ecb2a245c196d435a6d235b2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.1539 -  val loss 0.1467 AUC 0.7846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e701e04fe7a24bfdbc84a9d185a55420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - train loss 0.1402 -  val loss 0.1474 AUC 0.7900\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60c29511a1546cf975ab06090118632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - train loss 0.1379 -  val loss 0.1452 AUC 0.7984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fefb90c210c4b09ae5e9884551765a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - train loss 0.1339 -  val loss 0.1426 AUC 0.8193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e6c6b8297242bb9428e8d700d0074e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Whole dataset\n",
    "\n",
    "transforms=[random_rotation(arc_width=20), flip(), random_crop(r_pix=8)]\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=img_folder_path,transforms=transforms,\n",
    "                       shuffle=True, data=data, batch_size=batch_size, normalize=pretrained)\n",
    "\n",
    "model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "\n",
    "train(epochs, train_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataBatches(test_df,img_folder_path=img_folder_path, transforms = True, \n",
    "                      shuffle = False, data=data, batch_size = batch_size, normalize=pretrained)\n",
    "TTA_multilabel(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1)\n",
    "\n",
    "for N in [50, 100, 5_000, 10_000, 20_000, 35_000, 50_000, 60_000, 77_880]:\n",
    "    \n",
    "    sampled_train_df = train_df[:N]\n",
    "    \n",
    "    train_dl = DataBatches(train_df, img_folder_path=img_folder_path,\n",
    "                           transforms=True, shuffle=True, data=data,\n",
    "                           batch_size=batch_size, half=False, normalize=pretrained)\n",
    "    \n",
    "    model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "    save_path = SAVE_DIRECTORY/f\"{pretrained}-{N}.pth\"\n",
    "    # save_path = SAVE_DIRECTORY / f\"{pretrained}-{N}-{random_state}-unfreezing.pth\"\n",
    "    train(epochs, train_dl, valid_dl, model, max_lr=.001, save_path=save_path,unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20191780040408833,\n",
       " 0.8164163548894331,\n",
       " [0.7777638937179043,\n",
       "  0.8882716944725164,\n",
       "  0.8331421478637311,\n",
       "  0.6839344107757633,\n",
       "  0.8366145269199207,\n",
       "  0.7661666072832656,\n",
       "  0.7252368098300768,\n",
       "  0.8640024568362074,\n",
       "  0.752993899915239,\n",
       "  0.8507316063175169,\n",
       "  0.9233914222053733,\n",
       "  0.8275160380939851,\n",
       "  0.7879706132917902,\n",
       "  0.9120928409287741])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl = DataBatches(test_df,img_folder_path=img_folder_path,\n",
    "                  transforms = False, shuffle = False, data=data,\n",
    "                  batch_size = batch_size, normalize=pretrained)\n",
    "validate(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.2021 and auc 0.8210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20208021653882324, 0.8209861720227334)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl = DataBatches(test_df,img_folder_path=img_folder_path,\n",
    "                  transforms = True, shuffle = False, data=data,\n",
    "                  batch_size = batch_size, normalize=pretrained)\n",
    "TTA_test_metrics_chest(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d59bdd3bd748b7a5b5be93075f3db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e318da8cf059411bab4fb4570493ec7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.1535 -  val loss 0.1460 AUC 0.7735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33d6b526dbc4a52953733c89ed0d7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - train loss 0.1403 -  val loss 0.1490 AUC 0.7919\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958ad7d2cc65463190076328affb91a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - train loss 0.1379 -  val loss 0.1473 AUC 0.8027\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4460556e0dde4ad492b31361ec16b139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - train loss 0.1337 -  val loss 0.1427 AUC 0.8155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f299f3e060f54abbb40fe274b28e7ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 5 - train loss 0.1295 -  val loss 0.1388 AUC 0.8338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72631ddb5d34cde93fdbd38cf1358ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 6 - train loss 0.1251 -  val loss 0.1369 AUC 0.8358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f662b10fdb2849b18f2ed4e0a0eed2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 7 - train loss 0.1200 -  val loss 0.1369 AUC 0.8411\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83d2495e4394ad7bb0928883b010729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 38728 is out of bounds for axis 0 with size 38728",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-95249fe8f649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# save_path = SAVE_DIRECTORY / f\"{pretrained}-{N}-{random_state}-unfreezing.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munfreeze_during_loop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfreeze\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-a357c34d05eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, train_dl, valid_dl, model, div_factor, max_lr, wd, alpha, save_path, unfreeze_during_loop)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a357c34d05eb>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a357c34d05eb>\u001b[0m in \u001b[0;36m_update_optimizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mlr_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lr_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mparam_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-a357c34d05eb>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmom_schedule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 38728 is out of bounds for axis 0 with size 38728"
     ]
    }
   ],
   "source": [
    "model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "save_path = SAVE_DIRECTORY/f\"{pretrained}-77800.pth\"\n",
    "# save_path = SAVE_DIRECTORY / f\"{pretrained}-{N}-{random_state}-unfreezing.pth\"\n",
    "train(epochs, train_dl, valid_dl, model, max_lr=.001, save_path=save_path,unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d6fd4d43d747e6be558351c687e190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.1529 -  val loss 0.1456 AUC 0.7908\n",
      "Ep. 2 - train loss 0.1445 -  val loss 0.1478 AUC 0.7804\n",
      "Ep. 3 - train loss 0.1399 -  val loss 0.1457 AUC 0.7900\n",
      "Ep. 4 - train loss 0.1356 -  val loss 0.1409 AUC 0.8095\n",
      "Ep. 5 - train loss 0.1315 -  val loss 0.1398 AUC 0.8125\n",
      "Ep. 6 - train loss 0.1269 -  val loss 0.1382 AUC 0.8219\n",
      "Ep. 7 - train loss 0.1218 -  val loss 0.1373 AUC 0.8233\n",
      "Ep. 8 - train loss 0.1178 -  val loss 0.1374 AUC 0.8250\n"
     ]
    }
   ],
   "source": [
    "model = DenseNet(14, pretrained=pretrained, freeze=freeze).cuda()\n",
    "save_path = SAVE_DIRECTORY/f\"{pretrained}-77800-{random_state}.pth\"\n",
    "# save_path = SAVE_DIRECTORY / f\"{pretrained}-{N}-{random_state}-unfreezing.pth\"\n",
    "train(epochs, train_dl, valid_dl, model, max_lr=.001, save_path=save_path, bar=tqdm_notebook,\n",
    "      unfreeze_during_loop=(.1, .2) if freeze else None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
