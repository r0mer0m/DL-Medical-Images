{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all the available data\n",
    "## Imports & global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys; sys.path.append(\"/data/miguel/practicum/DL-Medical-Physics\")\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "from core import *\n",
    "from data_manipulation import DataBatches, RandomRotation, Flip, RandomCrop, balance_obs, multi_label_2_binary\n",
    "from utils import save_model, load_model, lr_loss_plot\n",
    "from architectures import DenseNet121\n",
    "from train_functions import get_optimizer, FinderPolicy, OptimizerWrapper, validate_binary, lr_finder, TTA_binary\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "TRANSFORMATIONS = [RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=8)]\n",
    "PRETRAINED = False\n",
    "FREEZE = False\n",
    "GRADUAL_UNFREEZING = False\n",
    "\n",
    "BASE_PATH = Path('/data/miguel/practicum/')\n",
    "PATH = BASE_PATH/'data'\n",
    "# SAVE_DATA = BASE_PATH/'output/real_data_experiments/multilabel/results'\n",
    "# SAVE_DIRECTORY = BASE_PATH/'output/real_data_experiments/multilabel/models'\n",
    "# SAVE_PLOT = Path('../latest_plots/14diseases-app1')\n",
    "\n",
    "IMG_FOLDER = PATH/'ChestXRay-250'\n",
    "DATA = 'Pneumonia'\n",
    "DISEASE = 'Emphysema'\n",
    "\n",
    "idx2tgt = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "tgt2idx = {disease: i for i, disease in enumerate(idx2tgt)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data preparation\n",
    "train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "train_df = multi_label_2_binary(train_df, tgt2idx[DISEASE])\n",
    "\n",
    "valid_df = multi_label_2_binary(valid_df, tgt2idx[DISEASE])\n",
    "valid_df = balance_obs(valid_df, amt=2*len(valid_df[valid_df['Label']==1]))\n",
    "\n",
    "test_df = multi_label_2_binary(test_df, tgt2idx[DISEASE])\n",
    "test_df = balance_obs(test_df, amt=2*len(test_df[test_df['Label']==1]))\n",
    "\n",
    "\n",
    "train_dl = DataBatches(train_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS, \n",
    "                       shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "valid_dl = DataBatches(valid_df,img_folder_path=IMG_FOLDER, transforms = False,\n",
    "                       shuffle = False, data=DATA, batch_size = BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms = TRANSFORMATIONS, \n",
    "                      shuffle = False, data=DATA, batch_size = BATCH_SIZE, normalize=PRETRAINED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607d278012294cf78199325f6832ba57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17483704d4434852ba2997847b4e8d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEaCAYAAADqqhd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_df = balance_obs(train_df, amt=2000)\n",
    "\n",
    "model = DenseNet121(1, pretrained=PRETRAINED, freeze=FREEZE).cuda()\n",
    "lrs, losses  = lr_finder(model, 1, train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training loop: definition\n",
    "def regular_training(epochs, train_dl, valid_dl, model, save_path=None,\n",
    "          min_lr=1e-6, max_lr=0.001, epsilon=.001, unfreeze_during_loop:tuple=None):\n",
    "    lr = max_lr\n",
    "    prev_loss, min_loss = np.inf, np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "        \n",
    "    \n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "        model.train()\n",
    "        train_dl.set_random_choices()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        optim = get_optimizer(model, lr=lr, wd=0)\n",
    "        for x, y in tqdm_notebook(train_dl, leave=False):\n",
    "            \n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            out = model(x).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total += batch\n",
    "            sum_loss += batch * (loss.item())\n",
    "            \n",
    "            cnt += 1\n",
    "                \n",
    "        val_loss, measure, _ = validate_binary(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - lr {lr:.7f} train loss {sum_loss/total:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if val_loss - prev_loss > epsilon:\n",
    "            lr = lr / 10.0\n",
    "        if val_loss < min_loss:\n",
    "            if save_path: save_model(model, save_path)\n",
    "            min_loss = val_loss\n",
    "        prev_loss = val_loss\n",
    "        if lr < min_lr:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_annealing(start_lr, end_lr, n_iterations):\n",
    "    i = np.arange(n_iterations)\n",
    "    c_i = 1 + np.cos(i * np.pi / n_iterations)\n",
    "    return end_lr + (start_lr - end_lr) / 2 * c_i\n",
    "\n",
    "class TrainingPolicy:\n",
    "    '''Cretes the lr and momentum policy'''\n",
    "\n",
    "    def __init__(self, n_epochs, dl, max_lr, pctg=.3, moms=(.95, .85),\n",
    "                 delta=1e-4, div_factor=25.):\n",
    "        \n",
    "        total_iterations = n_epochs * len(dl)\n",
    "\n",
    "        iter1 = int(total_iterations * pctg)\n",
    "        iter2 = total_iterations - int(total_iterations * pctg)\n",
    "        iterations = (iter1, iter2)\n",
    "\n",
    "        min_start = max_lr / div_factor\n",
    "        min_end = min_start * delta\n",
    "\n",
    "        lr_segments = ((min_start, max_lr), (max_lr, min_end))\n",
    "        mom_segments = (moms, (moms[1], moms[0]))\n",
    "\n",
    "        self.lr_schedule = self._create_schedule(lr_segments, iterations)\n",
    "        self.mom_schedule = self._create_schedule(mom_segments, iterations)\n",
    "\n",
    "        self.idx = -1\n",
    "\n",
    "    def _create_schedule(self, segments, iterations):\n",
    "        '''\n",
    "        Creates a schedule given a function, behaviour and size\n",
    "        '''\n",
    "        stages = [cos_annealing(start, end, n) for ((start, end), n) in zip(segments, iterations)]\n",
    "        return np.concatenate(stages)\n",
    "\n",
    "    def step(self):\n",
    "        self.idx += 1\n",
    "        return self.lr_schedule[self.idx], self.mom_schedule[self.idx]\n",
    "    \n",
    "def one_cycle_train(n_epochs, train_dl, valid_dl, model, max_lr=.01, wd=0, alpha=1./ 3,\n",
    "          save_path=None, unfreeze_during_loop:tuple=None):\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "\n",
    "    best_loss = np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    policy = TrainingPolicy(n_epochs=n_epochs, dl=train_dl, max_lr=max_lr)\n",
    "    optimizer = OptimizerWrapper(model, policy, wd=wd, alpha=alpha)\n",
    "\n",
    "    for epoch in tqdm_notebook(range(n_epochs), ):\n",
    "        model.train()\n",
    "        agg_div = 0\n",
    "        agg_loss = 0\n",
    "        train_dl.set_random_choices()\n",
    "        for x, y in tqdm_notebook(train_dl, leave=False):\n",
    "\n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "\n",
    "            out = model(x).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            agg_loss += batch*loss.item()\n",
    "            agg_div += batch\n",
    "            cnt += 1\n",
    "\n",
    "\n",
    "        val_loss, measure, _ = validate_binary(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - train loss {agg_loss/agg_div:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if save_path and val_loss < best_loss:\n",
    "            save_model(model, save_path)\n",
    "            best_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d935ea0a7dff4866b01b36367ecd6ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3610888d5a5469b93e4a0351b22553b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - lr 0.0010000 train loss 0.7048 -  val loss 0.6644 AUC 0.6483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65daa3d5f6647559820d46562d95ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - lr 0.0010000 train loss 0.7030 -  val loss 0.6573 AUC 0.6729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7b937e4bd349938383769466c24ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - lr 0.0010000 train loss 0.6922 -  val loss 0.9214 AUC 0.5385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653efae56f2e4ad497232bc66e8fe278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - lr 0.0001000 train loss 0.6793 -  val loss 0.6545 AUC 0.6667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef4b53c3b0f40c282228f7eb587daed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 5 - lr 0.0001000 train loss 0.6720 -  val loss 0.6514 AUC 0.6724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8523a5112da84d8a85c88670c18abddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8aeadc69d77a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRETRAINED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFREEZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mregular_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-432a973a5920>\u001b[0m in \u001b[0;36mregular_training\u001b[0;34m(epochs, train_dl, valid_dl, model, save_path, min_lr, max_lr, epsilon, unfreeze_during_loop)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop: execution\n",
    "\n",
    "\n",
    "transforms=[RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=8)]\n",
    "\n",
    "sampled_df = balance_obs(train_df, amt=2000)\n",
    "\n",
    "train_dl = DataBatches(sampled_df, img_folder_path=IMG_FOLDER,transforms=TRANSFORMATIONS,\n",
    "                       shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "\n",
    "model = DenseNet121(1, pretrained=PRETRAINED, freeze=FREEZE).cuda()\n",
    "save_path = None\n",
    "regular_training(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load_model(model, save_path)\n",
    "# test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms = TRANSFORMATIONS, \n",
    "#                       shuffle = False, data=data, batch_size = BATCH_SIZE, normalize=PRETRAINED)\n",
    "# TTA_multilabel(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f4e21136ff423fb4a6685908aa4209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706f12a224484545a7ea02b1392751f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1 - train loss 0.6884 -  val loss 0.7046 AUC 0.5025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e784abd13a4ddeb365fffe6da0c0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 2 - train loss 0.6829 -  val loss 0.6728 AUC 0.6634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05ada991e604e4eb9f62059f007e8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 3 - train loss 0.6849 -  val loss 0.6429 AUC 0.6830\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe1f822547849ec87c9b6a6ee47c1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 4 - train loss 0.6918 -  val loss 0.6727 AUC 0.6699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26aeddaa96cb448a96e901b4d2faa933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 5 - train loss 0.6870 -  val loss 0.6961 AUC 0.6761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a05ed68789438c9c9ef4f6185a20e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 6 - train loss 0.6767 -  val loss 0.7312 AUC 0.6776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300e1596554f4151942adf15a945067d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c327483bf994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPRETRAINED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFREEZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mone_cycle_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfreeze_during_loop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mGRADUAL_UNFREEZING\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-0700f9fa73c3>\u001b[0m in \u001b[0;36mone_cycle_train\u001b[0;34m(n_epochs, train_dl, valid_dl, model, max_lr, wd, alpha, save_path, unfreeze_during_loop)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/practicum/DL-Medical-Physics/train_functions.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = DenseNet121(1, pretrained=PRETRAINED, freeze=FREEZE).cuda()\n",
    "save_path = None\n",
    "one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=None, unfreeze_during_loop=(.1, .2) if GRADUAL_UNFREEZING else None, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load_model(model, save_pathc)\n",
    "# test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms = TRANSFORMATIONS, \n",
    "#                       shuffle = False, data=DATA, batch_size = BATCH_SIZE, normalize=PRETRAINED)\n",
    "# TTA_multilabel(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample range: Writing script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the different combinations on a script. Observe that we have constructed the training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/miguel/practicum/DL-Medical-Physics/training_methods\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting emphysema.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile emphysema.py\n",
    "\n",
    "import sys; sys.path.append(\"/data/miguel/practicum/DL-Medical-Physics\")\n",
    "\n",
    "from core import *\n",
    "from data_manipulation import DataBatches, RandomRotation, Flip, RandomCrop, balance_obs, multi_label_2_binary\n",
    "from utils import save_model, load_model, lr_loss_plot\n",
    "from architectures import DenseNet121\n",
    "from train_functions import get_optimizer, FinderPolicy, OptimizerWrapper, validate_binary, TTA_binary\n",
    "import json\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "TRANSFORMATIONS = [RandomRotation(arc_width=20), Flip(), RandomCrop(r_pix=8)]\n",
    "DATA = 'Pneumonia'\n",
    "DISEASE = 'Emphysema'\n",
    "\n",
    "idx2tgt = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "               'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "tgt2idx = {disease: i for i, disease in enumerate(idx2tgt)}\n",
    "\n",
    "SAMPLE_AMOUNTS = [50,100,200,400,600,800,1000,1200,1400,1600,1800,2000]\n",
    "\n",
    "BASE_PATH = Path('/data/miguel/practicum/')\n",
    "PATH = BASE_PATH/'data'\n",
    "SAVE_DIRECTORY = BASE_PATH/'DL-Medical-Physics/training_methods/models'\n",
    "SAVE_DATA = BASE_PATH/'DL-Medical-Physics/training_methods/results'\n",
    "IMG_FOLDER = PATH/'ChestXRay-250'\n",
    "PRETRAINED = False\n",
    "FREEZE = False\n",
    "GRADUAL_UNFREEZING = False\n",
    "\n",
    "def regular_training(epochs, train_dl, valid_dl, model, save_path=None,\n",
    "          min_lr=1e-6, max_lr=0.001, epsilon=.001, unfreeze_during_loop:tuple=None):\n",
    "    lr = max_lr\n",
    "    prev_loss, min_loss = np.inf, np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "        \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_dl.set_random_choices()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        optim = get_optimizer(model, lr=lr, wd=0)\n",
    "        for x, y in train_dl:\n",
    "            \n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            out = model(x).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total += batch\n",
    "            sum_loss += batch * (loss.item())\n",
    "            \n",
    "            cnt += 1\n",
    "                \n",
    "        val_loss, measure, _ = validate_binary(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - lr {lr:.7f} train loss {sum_loss/total:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if val_loss - prev_loss > epsilon:\n",
    "            lr = lr / 10.0\n",
    "        if val_loss < min_loss:\n",
    "            if save_path: save_model(model, save_path)\n",
    "            min_loss = val_loss\n",
    "        prev_loss = val_loss\n",
    "        if lr < min_lr:\n",
    "            break\n",
    "            \n",
    "def cos_annealing(start_lr, end_lr, n_iterations):\n",
    "    i = np.arange(n_iterations)\n",
    "    c_i = 1 + np.cos(i * np.pi / n_iterations)\n",
    "    return end_lr + (start_lr - end_lr) / 2 * c_i\n",
    "\n",
    "class TrainingPolicy:\n",
    "    '''Cretes the lr and momentum policy'''\n",
    "\n",
    "    def __init__(self, n_epochs, dl, max_lr, pctg=.3, moms=(.95, .85),\n",
    "                 delta=1e-4, div_factor=25.):\n",
    "        \n",
    "        total_iterations = n_epochs * len(dl)\n",
    "\n",
    "        iter1 = int(total_iterations * pctg)\n",
    "        iter2 = total_iterations - int(total_iterations * pctg)\n",
    "        iterations = (iter1, iter2)\n",
    "\n",
    "        min_start = max_lr / div_factor\n",
    "        min_end = min_start * delta\n",
    "\n",
    "        lr_segments = ((min_start, max_lr), (max_lr, min_end))\n",
    "        mom_segments = (moms, (moms[1], moms[0]))\n",
    "\n",
    "        self.lr_schedule = self._create_schedule(lr_segments, iterations)\n",
    "        self.mom_schedule = self._create_schedule(mom_segments, iterations)\n",
    "\n",
    "        self.idx = -1\n",
    "\n",
    "    def _create_schedule(self, segments, iterations):\n",
    "        '''\n",
    "        Creates a schedule given a function, behaviour and size\n",
    "        '''\n",
    "        stages = [cos_annealing(start, end, n) for ((start, end), n) in zip(segments, iterations)]\n",
    "        return np.concatenate(stages)\n",
    "\n",
    "    def step(self):\n",
    "        self.idx += 1\n",
    "        return self.lr_schedule[self.idx], self.mom_schedule[self.idx]\n",
    "    \n",
    "def one_cycle_train(n_epochs, train_dl, valid_dl, model, max_lr=.01, wd=0, alpha=1./ 3,\n",
    "          save_path=None, unfreeze_during_loop:tuple=None):\n",
    "    \n",
    "    if unfreeze_during_loop:\n",
    "        total_iter = n_epochs*len(train_dl)\n",
    "        first_unfreeze = int(total_iter*unfreeze_during_loop[0])\n",
    "        second_unfreeze = int(total_iter*unfreeze_during_loop[1])\n",
    "\n",
    "    best_loss = np.inf\n",
    "    cnt = 0\n",
    "    \n",
    "    policy = TrainingPolicy(n_epochs=n_epochs, dl=train_dl, max_lr=max_lr)\n",
    "    optimizer = OptimizerWrapper(model, policy, wd=wd, alpha=alpha)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        agg_div = 0\n",
    "        agg_loss = 0\n",
    "        train_dl.set_random_choices()\n",
    "        for x, y in train_dl:\n",
    "\n",
    "            if unfreeze_during_loop:\n",
    "                if cnt == first_unfreeze: model.unfreeze(1)\n",
    "                if cnt == second_unfreeze: model.unfreeze(0)\n",
    "\n",
    "            out = model(x).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(input=out, target=y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch = y.shape[0]\n",
    "            agg_loss += batch*loss.item()\n",
    "            agg_div += batch\n",
    "            cnt += 1\n",
    "\n",
    "\n",
    "        val_loss, measure, _ = validate_binary(model, valid_dl)\n",
    "        print(f'Ep. {epoch+1} - train loss {agg_loss/agg_div:.4f} -  val loss {val_loss:.4f} AUC {measure:.4f}')\n",
    "\n",
    "        if save_path and val_loss < best_loss:\n",
    "            save_model(model, save_path)\n",
    "            best_loss = val_loss\n",
    "\n",
    "# Training            \n",
    "train_df = pd.read_csv(PATH/\"train_df.csv\")\n",
    "valid_df = pd.read_csv(PATH/\"val_df.csv\")\n",
    "\n",
    "train_df = multi_label_2_binary(train_df, tgt2idx[DISEASE])\n",
    "\n",
    "valid_df = multi_label_2_binary(valid_df, tgt2idx[DISEASE])\n",
    "valid_df = balance_obs(valid_df, amt=2*len(valid_df[valid_df['Label']==1]))\n",
    "\n",
    "valid_dl = DataBatches(valid_df,img_folder_path=IMG_FOLDER,transforms=False, \n",
    "                       shuffle=False, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "train_df = train_df.sample(frac=1)\n",
    "\n",
    "for N in SAMPLE_AMOUNTS:\n",
    "\n",
    "    df = balance_obs(train_df, amt=N)\n",
    "\n",
    "    train_dl = DataBatches(df, img_folder_path=IMG_FOLDER, transforms=TRANSFORMATIONS, \n",
    "                           shuffle=True, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "    model = DenseNet121(1, pretrained=PRETRAINED, freeze=FREEZE).cuda()\n",
    "\n",
    "    save_path = SAVE_DIRECTORY/f\"{DISEASE.lower()}-regular-training-{N}.pth\"\n",
    "\n",
    "    regular_training(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=save_path)\n",
    "    \n",
    "    model = DenseNet121(1, pretrained=PRETRAINED, freeze=FREEZE).cuda()\n",
    "\n",
    "    save_path = SAVE_DIRECTORY/f\"{DISEASE.lower()}-one-cycle-training-{N}.pth\"\n",
    "    \n",
    "    one_cycle_train(EPOCHS, train_dl, valid_dl, model, max_lr=.001, save_path=save_path, unfreeze_during_loop=(.1, .2) if GRADUAL_UNFREEZING else None, alpha=1)\n",
    "    \n",
    "    \n",
    "# Evaluation\n",
    "\n",
    "test_df = pd.read_csv(PATH/\"test_df.csv\")\n",
    "\n",
    "test_df = multi_label_2_binary(test_df, tgt2idx[DISEASE])\n",
    "test_df = balance_obs(test_df, amt=2*len(test_df[test_df['Label']==1]))\n",
    "\n",
    "regular_training = {\n",
    "    'losses':[],\n",
    "    'aucs':[]\n",
    "}\n",
    "one_cycle_training = {\n",
    "    'losses':[],\n",
    "    'aucs':[]\n",
    "}\n",
    "\n",
    "test_dl = DataBatches(test_df,img_folder_path=IMG_FOLDER, transforms=TRANSFORMATIONS, \n",
    "                      shuffle=False, data=DATA, batch_size=BATCH_SIZE, normalize=PRETRAINED)\n",
    "\n",
    "for i, N in enumerate(SAMPLE_AMOUNTS):\n",
    "\n",
    "    model = DenseNet121(1, pretrained=PRETRAINED, freeze=FREEZE).cuda()\n",
    "\n",
    "    load_path = SAVE_DIRECTORY/f\"{DISEASE.lower()}-regular-training-{N}.pth\"\n",
    "\n",
    "    load_model(model, load_path)\n",
    "\n",
    "    loss, mean_auc, _ = TTA_binary(model, test_dl, ndl=4)\n",
    "\n",
    "    regular_training['losses'].append(loss)\n",
    "    regular_training['aucs'].append(mean_auc)\n",
    "\n",
    "    load_path = SAVE_DIRECTORY/f\"{DISEASE.lower()}-one-cycle-training-{N}.pth\"\n",
    "\n",
    "    load_model(model, load_path)\n",
    "\n",
    "    loss, mean_auc, _ = TTA_binary(model, test_dl, ndl=4)\n",
    "\n",
    "    one_cycle_training['losses'].append(loss)\n",
    "    one_cycle_training['aucs'].append(mean_auc)\n",
    "\n",
    "regular_training = json.dumps(regular_training)\n",
    "with open(f'results/{DISEASE.lower()}_regular_training.json', 'w') as f:\n",
    "    f.write(regular_training)\n",
    "\n",
    "one_cycle_training = json.dumps(one_cycle_training)\n",
    "with open(f'results/{DISEASE.lower()}_one_cycle_training.json', 'w') as f:\n",
    "    f.write(one_cycle_training)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
